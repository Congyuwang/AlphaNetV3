<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 7.2.0" />
    <title>alphanet API documentation</title>
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2264%22%20height%3D%2264%22%20viewBox%3D%2244.5%202.5%2015%2015%22%3E%3Cpath%20d%3D%22M49.351%2021.041c-.233-.721-.546-2.408-.772-4.076-.042-.09-.067-.187-.046-.288-.166-1.347-.277-2.625-.241-3.351-1.378-1.008-2.271-2.586-2.271-4.362%200-.976.272-1.935.788-2.774.057-.094.122-.18.184-.268-.033-.167-.052-.339-.052-.516%200-1.477%201.202-2.679%202.679-2.679.791%200%201.496.352%201.987.9a6.3%206.3%200%200%201%201.001.029c.492-.564%201.207-.929%202.012-.929%201.477%200%202.679%201.202%202.679%202.679a2.65%202.65%200%200%201-.269%201.148c.383.747.595%201.572.595%202.41%200%202.311-1.507%204.29-3.635%205.107.037.699.147%202.27.423%203.294l.137.461c.156%202.136-4.612%205.166-5.199%203.215zm.127-4.919a4.78%204.78%200%200%200%20.775-.584c-.172-.115-.505-.254-.88-.378zm.331%202.302l.828-.502c-.202-.143-.576-.328-.984-.49zm.45%202.157l.701-.403c-.214-.115-.536-.249-.891-.376l.19.779zM49.13%204.141c0%20.152.123.276.276.276s.275-.124.275-.276-.123-.276-.276-.276-.275.124-.275.276zm.735-.389a1.15%201.15%200%200%201%20.314.783%201.16%201.16%200%200%201-1.162%201.162c-.457%200-.842-.27-1.032-.653-.026.117-.042.238-.042.362a1.68%201.68%200%200%200%201.679%201.679%201.68%201.68%200%200%200%201.679-1.679c0-.843-.626-1.535-1.436-1.654zm3.076%201.654a1.68%201.68%200%200%200%201.679%201.679%201.68%201.68%200%200%200%201.679-1.679c0-.037-.009-.072-.011-.109-.21.3-.541.508-.935.508a1.16%201.16%200%200%201-1.162-1.162%201.14%201.14%200%200%201%20.474-.912c-.015%200-.03-.005-.045-.005-.926.001-1.679.754-1.679%201.68zm1.861-1.265c0%20.152.123.276.276.276s.275-.124.275-.276-.123-.276-.276-.276-.275.124-.275.276zm1.823%204.823c0-.52-.103-1.035-.288-1.52-.466.394-1.06.64-1.717.64-1.144%200-2.116-.725-2.499-1.738-.383%201.012-1.355%201.738-2.499%201.738-.867%200-1.631-.421-2.121-1.062-.307.605-.478%201.267-.478%201.942%200%202.486%202.153%204.51%204.801%204.51s4.801-2.023%204.801-4.51zm-3.032%209.156l-.146-.492c-.276-1.02-.395-2.457-.444-3.268a6.11%206.11%200%200%201-1.18.115%206.01%206.01%200%200%201-2.536-.562l.006.175c.802.215%201.848.612%202.021%201.25.079.295-.021.601-.274.837l-.598.501c.667.304%201.243.698%201.311%201.179.02.144.022.507-.393.787l-.564.365c1.285.521%201.361.96%201.381%201.126.018.142.011.496-.427.746l-.854.489c.064-1.19%201.985-2.585%202.697-3.248zM49.34%209.925c0-.667%201-.667%201%200%200%20.653.818%201.205%201.787%201.205s1.787-.552%201.787-1.205c0-.667%201-.667%201%200%200%201.216-1.25%202.205-2.787%202.205s-2.787-.989-2.787-2.205zm-.887-7.633c-.093.077-.205.114-.317.114a.5.5%200%200%201-.318-.886L49.183.397a.5.5%200%200%201%20.703.068.5.5%200%200%201-.069.703zm7.661-.065c-.086%200-.173-.022-.253-.068l-1.523-.893c-.575-.337-.069-1.2.506-.863l1.523.892a.5.5%200%200%201%20.179.685c-.094.158-.261.247-.432.247z%22%20fill%3D%22%233bb300%22/%3E%3C/svg%3E"/>


<style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
<style>/*! pygments syntax highlighting */pre{line-height:125%;}td.linenos pre{color:#000000; background-color:#f0f0f0; padding-left:5px; padding-right:5px;}span.linenos{color:#000000; background-color:#f0f0f0; padding-left:5px; padding-right:5px;}td.linenos pre.special{color:#000000; background-color:#ffffc0; padding-left:5px; padding-right:5px;}span.linenos.special{color:#000000; background-color:#ffffc0; padding-left:5px; padding-right:5px;}.pdoc .hll{background-color:#ffffcc}.pdoc{background:#f8f8f8;}.pdoc .c{color:#408080; font-style:italic}.pdoc .err{border:1px solid #FF0000}.pdoc .k{color:#008000; font-weight:bold}.pdoc .o{color:#666666}.pdoc .ch{color:#408080; font-style:italic}.pdoc .cm{color:#408080; font-style:italic}.pdoc .cp{color:#BC7A00}.pdoc .cpf{color:#408080; font-style:italic}.pdoc .c1{color:#408080; font-style:italic}.pdoc .cs{color:#408080; font-style:italic}.pdoc .gd{color:#A00000}.pdoc .ge{font-style:italic}.pdoc .gr{color:#FF0000}.pdoc .gh{color:#000080; font-weight:bold}.pdoc .gi{color:#00A000}.pdoc .go{color:#888888}.pdoc .gp{color:#000080; font-weight:bold}.pdoc .gs{font-weight:bold}.pdoc .gu{color:#800080; font-weight:bold}.pdoc .gt{color:#0044DD}.pdoc .kc{color:#008000; font-weight:bold}.pdoc .kd{color:#008000; font-weight:bold}.pdoc .kn{color:#008000; font-weight:bold}.pdoc .kp{color:#008000}.pdoc .kr{color:#008000; font-weight:bold}.pdoc .kt{color:#B00040}.pdoc .m{color:#666666}.pdoc .s{color:#BA2121}.pdoc .na{color:#7D9029}.pdoc .nb{color:#008000}.pdoc .nc{color:#0000FF; font-weight:bold}.pdoc .no{color:#880000}.pdoc .nd{color:#AA22FF}.pdoc .ni{color:#999999; font-weight:bold}.pdoc .ne{color:#D2413A; font-weight:bold}.pdoc .nf{color:#0000FF}.pdoc .nl{color:#A0A000}.pdoc .nn{color:#0000FF; font-weight:bold}.pdoc .nt{color:#008000; font-weight:bold}.pdoc .nv{color:#19177C}.pdoc .ow{color:#AA22FF; font-weight:bold}.pdoc .w{color:#bbbbbb}.pdoc .mb{color:#666666}.pdoc .mf{color:#666666}.pdoc .mh{color:#666666}.pdoc .mi{color:#666666}.pdoc .mo{color:#666666}.pdoc .sa{color:#BA2121}.pdoc .sb{color:#BA2121}.pdoc .sc{color:#BA2121}.pdoc .dl{color:#BA2121}.pdoc .sd{color:#BA2121; font-style:italic}.pdoc .s2{color:#BA2121}.pdoc .se{color:#BB6622; font-weight:bold}.pdoc .sh{color:#BA2121}.pdoc .si{color:#BB6688; font-weight:bold}.pdoc .sx{color:#008000}.pdoc .sr{color:#BB6688}.pdoc .s1{color:#BA2121}.pdoc .ss{color:#19177C}.pdoc .bp{color:#008000}.pdoc .fm{color:#0000FF}.pdoc .vc{color:#19177C}.pdoc .vg{color:#19177C}.pdoc .vi{color:#19177C}.pdoc .vm{color:#19177C}.pdoc .il{color:#666666}</style>
<style>/*! pdoc */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f7f7f7;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}body{background-color:var(--pdoc-background);}html, body{width:100%;height:100%;}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}.git-button{display:none !important;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}#navtoggle{display:none;}}#togglestate{display:none;}nav.pdoc{--pad:1.75rem;--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent }nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc li{display:block;margin:0;padding:.2rem 0 .2rem var(--indent);transition:all 100ms;}nav.pdoc > div > ul > li{padding-left:0;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}html, main{scroll-behavior:smooth;}.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{background-color:var(--code);border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--code);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.pdoc details{--shift:-40px;text-align:right;margin-top:var(--shift);margin-bottom:calc(0px - var(--shift));clear:both;filter:opacity(1);}.pdoc details:not([open]){height:0;overflow:visible;}.pdoc details > summary{font-size:.75rem;cursor:pointer;color:var(--muted);border-width:0;padding:0 .7em;display:inline-block;display:inline list-item;user-select:none;}.pdoc details > summary:focus{outline:0;}.pdoc details > div{margin-top:calc(0px - var(--shift) / 2);text-align:left;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc > section:first-of-type > .docstring{margin-bottom:3rem;}.pdoc .docstring pre{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc .headerlink{position:absolute;width:0;margin-left:-1.5rem;line-height:1.4rem;font-size:1.5rem;font-weight:normal;transition:all 100ms ease-in-out;opacity:0;}.pdoc .attr > .headerlink{margin-left:-2.5rem;}.pdoc *:hover > .headerlink,.pdoc *:target > .attr > .headerlink{opacity:1;}.pdoc .attr{display:block;color:var(--text);margin:1rem 0 .5rem;padding:.4rem 5rem .4rem 1rem;background-color:var(--accent);}.pdoc .classattr{margin-left:2rem;}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{white-space:pre-wrap;}.pdoc .annotation{color:var(--annotation);}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}</style>
</head>
<body>        <nav class="pdoc">
            <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
            <input id="togglestate" type="checkbox">
            <div>
                        <a class="pdoc-button module-list-button" href="./">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                            &nbsp;
                            Module Index
                        </a>

                        <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                               pattern=".+" required>




                    <h2>API Documentation</h2>
                        <ul class="memberlist">
            <li>
                    <a class="class" href="#Std">Std</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#Std.__init__">Std</a>
                        </li>
                        <li>
                                <a class="function" href="#Std.build">build</a>
                        </li>
                        <li>
                                <a class="function" href="#Std.call">call</a>
                        </li>
                        <li>
                                <a class="function" href="#Std.get_config">get_config</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#Return">Return</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#Return.__init__">Return</a>
                        </li>
                        <li>
                                <a class="function" href="#Return.build">build</a>
                        </li>
                        <li>
                                <a class="function" href="#Return.call">call</a>
                        </li>
                        <li>
                                <a class="function" href="#Return.get_config">get_config</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#Correlation">Correlation</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#Correlation.call">call</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#LinearDecay">LinearDecay</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#LinearDecay.__init__">LinearDecay</a>
                        </li>
                        <li>
                                <a class="function" href="#LinearDecay.build">build</a>
                        </li>
                        <li>
                                <a class="function" href="#LinearDecay.call">call</a>
                        </li>
                        <li>
                                <a class="function" href="#LinearDecay.get_config">get_config</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#Covariance">Covariance</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#Covariance.call">call</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ZScore">ZScore</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ZScore.__init__">ZScore</a>
                        </li>
                        <li>
                                <a class="function" href="#ZScore.build">build</a>
                        </li>
                        <li>
                                <a class="function" href="#ZScore.call">call</a>
                        </li>
                        <li>
                                <a class="function" href="#ZScore.get_config">get_config</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#FeatureExpansion">FeatureExpansion</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#FeatureExpansion.__init__">FeatureExpansion</a>
                        </li>
                        <li>
                                <a class="function" href="#FeatureExpansion.call">call</a>
                        </li>
                        <li>
                                <a class="function" href="#FeatureExpansion.get_config">get_config</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#AlphaNetV3">AlphaNetV3</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#AlphaNetV3.__init__">AlphaNetV3</a>
                        </li>
                        <li>
                                <a class="function" href="#AlphaNetV3.call">call</a>
                        </li>
                        <li>
                                <a class="function" href="#AlphaNetV3.compile">compile</a>
                        </li>
                        <li>
                                <a class="function" href="#AlphaNetV3.get_config">get_config</a>
                        </li>
                </ul>

            </li>
    </ul>


                    <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev">
                        built with <span class="visually-hidden">pdoc</span><img
                            alt="pdoc logo"
                            src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
                    </a>
            </div>
        </nav>
    <main class="pdoc">
            <section>
                    <h1 class="modulename">
alphanet    </h1>

                        <div class="docstring"><p>复现华泰金工 alpha net V3 版本.</p>

<pre><code>input: (batch_size, history time steps, features)

                stride = 5
        +-&gt; expand features -&gt; BN -&gt; GRU -&gt; BN -+
input --|       stride = 10                     |- concat -&gt; Dense(linear)
        +-&gt; expand features -&gt; BN -&gt; GRU -&gt; BN -+
</code></pre>

<p>(BN: batch normalization)</p>

<p>version: 0.0.2</p>

<p>author: Congyu Wang</p>

<p>date: 2021-07-29</p>

<p>该module定义了计算不同时间序列特征的层，工程上使用tensorflow
进行高度向量化的计算，训练时较高效。</p>
</div>

                        <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="sd">&quot;&quot;&quot;复现华泰金工 alpha net V3 版本.</span>

<span class="sd">```</span>
<span class="sd">input: (batch_size, history time steps, features)</span>

<span class="sd">                stride = 5</span>
<span class="sd">        +-&gt; expand features -&gt; BN -&gt; GRU -&gt; BN -+</span>
<span class="sd">input --|       stride = 10                     |- concat -&gt; Dense(linear)</span>
<span class="sd">        +-&gt; expand features -&gt; BN -&gt; GRU -&gt; BN -+</span>
<span class="sd">```</span>

<span class="sd">(BN: batch normalization)</span>

<span class="sd">version: 0.0.2</span>

<span class="sd">author: Congyu Wang</span>

<span class="sd">date: 2021-07-29</span>

<span class="sd">该module定义了计算不同时间序列特征的层，工程上使用tensorflow</span>
<span class="sd">进行高度向量化的计算，训练时较高效。</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">_tf</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras.layers</span> <span class="k">as</span> <span class="nn">_tfl</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Layer</span> <span class="k">as</span> <span class="n">_Layer</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.initializers</span> <span class="kn">import</span> <span class="n">Initializer</span> <span class="k">as</span> <span class="n">_Initializer</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span> <span class="k">as</span> <span class="n">_Model</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span> <span class="k">as</span> <span class="n">_ABC</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">abstractmethod</span> <span class="k">as</span> <span class="n">_abstractmethod</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Std&quot;</span><span class="p">,</span>
           <span class="s2">&quot;Return&quot;</span><span class="p">,</span>
           <span class="s2">&quot;Correlation&quot;</span><span class="p">,</span>
           <span class="s2">&quot;LinearDecay&quot;</span><span class="p">,</span>
           <span class="s2">&quot;Covariance&quot;</span><span class="p">,</span>
           <span class="s2">&quot;ZScore&quot;</span><span class="p">,</span>
           <span class="s2">&quot;FeatureExpansion&quot;</span><span class="p">,</span>
           <span class="s2">&quot;AlphaNetV3&quot;</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">Std</span><span class="p">(</span><span class="n">_Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;每个序列各个stride的标准差.</span>

<span class="sd">    Notes:</span>
<span class="sd">        计算每个feature各个stride的standard deviation</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;标准差.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Std</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;构建该层，计算维度信息.&quot;&quot;&quot;</span>
        <span class="p">(</span><span class="n">features</span><span class="p">,</span>
         <span class="n">output_length</span><span class="p">)</span> <span class="o">=</span> <span class="n">__get_dimensions__</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                   <span class="n">output_length</span><span class="p">,</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                   <span class="n">features</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride, features)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute means for each stride</span>
        <span class="n">means</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
            <span class="n">_tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                            <span class="n">ksize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                            <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>

        <span class="c1"># subtract means for each stride</span>
        <span class="n">squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">_tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">means</span><span class="p">))</span>
        <span class="n">squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">squared_diff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">)</span>

        <span class="c1"># compute standard deviation for each stride</span>
        <span class="n">mean_squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">squared_diff</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_diff</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">std</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>


<span class="k">class</span> <span class="nc">ZScore</span><span class="p">(</span><span class="n">_Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;每个序列各个stride的均值除以其标准差.</span>

<span class="sd">    Notes:</span>
<span class="sd">        并非严格意义上的z-score,</span>
<span class="sd">        计算公式为每个feature各个stride的mean除以各自的standard deviation</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;均值除以标准差.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ZScore</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;构建该层，计算维度信息.&quot;&quot;&quot;</span>
        <span class="p">(</span><span class="n">features</span><span class="p">,</span>
         <span class="n">output_length</span><span class="p">)</span> <span class="o">=</span> <span class="n">__get_dimensions__</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                   <span class="n">output_length</span><span class="p">,</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                   <span class="n">features</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride, features)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute means for each stride</span>
        <span class="n">means</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                <span class="n">ksize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">)</span>

        <span class="c1"># compute standard deviations for each stride</span>
        <span class="n">means_broadcast</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">_tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">means_broadcast</span><span class="p">))</span>
        <span class="n">squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">squared_diff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">)</span>
        <span class="n">mean_squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">squared_diff</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_diff</span><span class="p">)</span>

        <span class="c1"># divide means by standard deviations for each stride</span>
        <span class="n">z_score</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">divide_no_nan</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z_score</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>


<span class="k">class</span> <span class="nc">LinearDecay</span><span class="p">(</span><span class="n">_Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;每个序列各个stride的线性衰减加权平均.</span>

<span class="sd">    Notes:</span>
<span class="sd">        以线性衰减为权重，计算每个feature各个stride的均值：</span>
<span class="sd">        如stride为10，则某feature该stride的权重为(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;线性递减加权平均.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearDecay</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;构建该层，计算维度信息.&quot;&quot;&quot;</span>
        <span class="p">(</span><span class="n">features</span><span class="p">,</span>
         <span class="n">output_length</span><span class="p">)</span> <span class="o">=</span> <span class="n">__get_dimensions__</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_length</span><span class="p">,</span> <span class="n">features</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">features</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride, features)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># get linear decay kernel</span>
        <span class="n">single_kernel</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">single_kernel</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span> <span class="o">/</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">single_kernel</span><span class="p">)</span>

        <span class="c1"># reshape tensors into:</span>
        <span class="c1"># (bash_size * (time_steps / stride), stride, features)</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">)</span>

        <span class="c1"># broadcasting kernel to inputs batch dimension</span>
        <span class="n">linear_decay</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">kernel</span> <span class="o">*</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">linear_decay</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">linear_decay</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">linear_decay</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>


<span class="k">class</span> <span class="nc">Return</span><span class="p">(</span><span class="n">_Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;每个序列各个stride的回报率.</span>

<span class="sd">    Notes:</span>
<span class="sd">        计算公式为每个stride最后一个数除以第一个数再减去一</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;回报率.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Return</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;构建该层，计算维度信息.&quot;&quot;&quot;</span>
        <span class="n">time_steps</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">time_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Error, time_steps 应该是 stride的整数倍&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride, features)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># get the endings of each strides as numerators</span>
        <span class="n">numerators</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)::</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="p">:]</span>

        <span class="c1"># get the beginnings of each strides as denominators</span>
        <span class="n">denominators</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="p">:]</span>

        <span class="k">return</span> <span class="n">_tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">divide_no_nan</span><span class="p">(</span><span class="n">numerators</span><span class="p">,</span> <span class="n">denominators</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.0</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>


<span class="k">class</span> <span class="nc">_OuterProductLayer</span><span class="p">(</span><span class="n">_Layer</span><span class="p">,</span> <span class="n">_ABC</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;外乘类的扩张层.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_OuterProductLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lower_mask</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;构建该层，计算维度信息.&quot;&quot;&quot;</span>
        <span class="p">(</span><span class="n">features</span><span class="p">,</span>
         <span class="n">output_length</span><span class="p">)</span> <span class="o">=</span> <span class="n">__get_dimensions__</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">features</span><span class="p">)</span>
        <span class="n">output_features</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">features</span> <span class="o">*</span> <span class="p">(</span><span class="n">features</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_length</span><span class="p">,</span> <span class="n">output_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lower_mask</span> <span class="o">=</span> <span class="n">_LowerNoDiagonalMask</span><span class="p">()((</span><span class="n">features</span><span class="p">,</span> <span class="n">features</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>

    <span class="nd">@_abstractmethod</span>
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;逻辑实现部分.&quot;&quot;&quot;</span>
        <span class="o">...</span>


<span class="k">class</span> <span class="nc">Covariance</span><span class="p">(</span><span class="n">_OuterProductLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;每个stride各个时间序列的covariance.</span>

<span class="sd">    Notes:</span>
<span class="sd">        计算每个stride每两个feature之间的covariance大小，</span>
<span class="sd">        输出feature数量为features * (features - 1) / 2</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride,</span>
<span class="sd">            features * (features - 1) / 2)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute means for each stride</span>
        <span class="n">means</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                <span class="n">ksize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">)</span>

        <span class="c1"># subtract means for each stride</span>
        <span class="n">means_broadcast</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">means_subtracted</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">means_broadcast</span><span class="p">)</span>
        <span class="n">means_subtracted</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">means_subtracted</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">)</span>

        <span class="c1"># compute covariance matrix</span>
        <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ijk,ijm-&gt;ikm&quot;</span><span class="p">,</span>
                                       <span class="n">means_subtracted</span><span class="p">,</span>
                                       <span class="n">means_subtracted</span><span class="p">)</span>
        <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">covariance_matrix</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># get the lower part of the covariance matrix</span>
        <span class="c1"># without the diagonal elements</span>
        <span class="n">covariances</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">covariance_matrix</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">lower_mask</span><span class="p">,</span>
                                       <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">covariances</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">covariances</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">covariances</span>


<span class="k">class</span> <span class="nc">Correlation</span><span class="p">(</span><span class="n">_OuterProductLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;每个stride各个时间序列的相关系数.</span>

<span class="sd">    Notes:</span>
<span class="sd">        计算每个stride每两个feature之间的correlation coefficient，</span>
<span class="sd">        输出feature数量为features * (features - 1) / 2</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride,</span>
<span class="sd">            features * (features - 1) / 2)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute means for each stride</span>
        <span class="n">means</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                <span class="n">ksize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">)</span>

        <span class="c1"># subtract means for each stride</span>
        <span class="n">means_broadcast</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">means_subtracted</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">means_broadcast</span><span class="p">)</span>
        <span class="n">means_subtracted</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">means_subtracted</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">)</span>

        <span class="c1"># compute standard deviations for each strides</span>
        <span class="n">squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">means_subtracted</span><span class="p">)</span>
        <span class="n">mean_squared_error</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">squared_diff</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">)</span>

        <span class="c1"># get denominator of correlation matrix</span>
        <span class="n">denominator_matrix</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ik,im-&gt;ikm&quot;</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>

        <span class="c1"># compute covariance matrix</span>
        <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ijk,ijm-&gt;ikm&quot;</span><span class="p">,</span>
                                       <span class="n">means_subtracted</span><span class="p">,</span>
                                       <span class="n">means_subtracted</span><span class="p">)</span>
        <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">covariance_matrix</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span>

        <span class="c1"># take the lower triangle of each matrix without diagonal</span>
        <span class="n">covariances</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">covariance_matrix</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">lower_mask</span><span class="p">,</span>
                                       <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">denominators</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">denominator_matrix</span><span class="p">,</span>
                                        <span class="bp">self</span><span class="o">.</span><span class="n">lower_mask</span><span class="p">,</span>
                                        <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">correlations</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">divide_no_nan</span><span class="p">(</span><span class="n">covariances</span><span class="p">,</span> <span class="n">denominators</span><span class="p">)</span>
        <span class="n">correlations</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">correlations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">correlations</span>


<span class="k">class</span> <span class="nc">FeatureExpansion</span><span class="p">(</span><span class="n">_Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;时间序列特征扩张层.</span>

<span class="sd">    Notes:</span>
<span class="sd">        该层扩张时间序列的feature数量，并通过stride缩短时间序列长度，</span>
<span class="sd">        其包括一下一些feature:</span>

<span class="sd">            - standard deviation</span>

<span class="sd">            - mean / standard deviation</span>

<span class="sd">            - linear decay average</span>

<span class="sd">            - return of each stride</span>

<span class="sd">            - covariance of each two features for each stride</span>

<span class="sd">            - correlation coefficient of each two features for each stride</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;时间序列特征扩张.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">int</span> <span class="ow">or</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be an integer &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FeatureExpansion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">Std</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z_score</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">ZScore</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_decay</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">LinearDecay</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">Return</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covariance</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">Covariance</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">Correlation</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride,</span>
<span class="sd">            features * (features + 3))</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">std_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">z_score_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">z_score</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">decay_linear_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_decay</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">return_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">covariance_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covariance</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">correlation_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">correlation</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">std_output</span><span class="p">,</span>
                           <span class="n">z_score_output</span><span class="p">,</span>
                           <span class="n">decay_linear_output</span><span class="p">,</span>
                           <span class="n">return_output</span><span class="p">,</span>
                           <span class="n">covariance_output</span><span class="p">,</span>
                           <span class="n">correlation_output</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>


<span class="k">class</span> <span class="nc">AlphaNetV3</span><span class="p">(</span><span class="n">_Model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;alpha net v3版本模型.</span>

<span class="sd">    Notes:</span>
<span class="sd">        复现华泰金工 alpha net V3 版本</span>
<span class="sd">        ::</span>

<span class="sd">            input: (batch_size, history time steps, features)</span>

<span class="sd">                            stride = 5</span>
<span class="sd">                    +-&gt; expand -&gt; BN -&gt; GRU -&gt; BN -+</span>
<span class="sd">            input --|       stride = 10            |- concat -&gt; Dense(linear)</span>
<span class="sd">                    +-&gt; expand -&gt; BN -&gt; GRU -&gt; BN -+</span>

<span class="sd">        (BN: batch normalization)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                 <span class="n">l2</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                 <span class="o">*</span><span class="n">args</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Alpha net v3.</span>

<span class="sd">        Notes:</span>
<span class="sd">            alpha net v3 版本的全tensorflow实现，结构详见代码展开</span>

<span class="sd">        Args:</span>
<span class="sd">            dropout: 跟在特征扩张以及Batch Normalization之后的dropout，默认无dropout</span>
<span class="sd">            l2: 输出层的l2-regularization参数</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlphaNetV3</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l2</span> <span class="o">=</span> <span class="n">l2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expanded10</span> <span class="o">=</span> <span class="n">FeatureExpansion</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expanded5</span> <span class="o">=</span> <span class="n">FeatureExpansion</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized10</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized5</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout10</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout5</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru10</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru5</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized10_2</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized5_2</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">concat</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">_tfl</span><span class="o">.</span><span class="n">Concatenate</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
                                  <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;truncated_normal&quot;</span><span class="p">,</span>
                                  <span class="n">kernel_regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;计算逻辑实现.&quot;&quot;&quot;</span>
        <span class="n">expanded10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expanded10</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">expanded5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expanded5</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">normalized10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized10</span><span class="p">(</span><span class="n">expanded10</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">normalized5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized5</span><span class="p">(</span><span class="n">expanded5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">dropout10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout10</span><span class="p">(</span><span class="n">normalized10</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">dropout5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout5</span><span class="p">(</span><span class="n">normalized5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">gru10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru10</span><span class="p">(</span><span class="n">dropout10</span><span class="p">)</span>
        <span class="n">gru5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru5</span><span class="p">(</span><span class="n">dropout5</span><span class="p">)</span>
        <span class="n">normalized10_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized10_2</span><span class="p">(</span><span class="n">gru10</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">normalized5_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized5_2</span><span class="p">(</span><span class="n">gru5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">concat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">normalized10_2</span><span class="p">,</span> <span class="n">normalized5_2</span><span class="p">])</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">(</span><span class="n">concat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>

    <span class="k">def</span> <span class="nf">compile</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">_tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
                <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;MSE&quot;</span><span class="p">,</span>
                <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">loss_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">weighted_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">steps_per_execution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;设置优化器、loss、metric等.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                        <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                        <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
                        <span class="n">loss_weights</span><span class="o">=</span><span class="n">loss_weights</span><span class="p">,</span>
                        <span class="n">weighted_metrics</span><span class="o">=</span><span class="n">weighted_metrics</span><span class="p">,</span>
                        <span class="n">run_eagerly</span><span class="o">=</span><span class="n">run_eagerly</span><span class="p">,</span>
                        <span class="n">steps_per_execution</span><span class="o">=</span><span class="n">steps_per_execution</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;dropout&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
                       <span class="s1">&#39;l2&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>


<span class="k">class</span> <span class="nc">_LowerNoDiagonalMask</span><span class="p">(</span><span class="n">_Initializer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;获取不含对角元素的矩阵下三角mask.</span>

<span class="sd">    Notes:</span>
<span class="sd">        Provide a mask giving the lower triangular of a matrix</span>
<span class="sd">        without diagonal elements.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_LowerNoDiagonalMask</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;计算逻辑.&quot;&quot;&quot;</span>
        <span class="n">ones</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">mask_lower</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">band_part</span><span class="p">(</span><span class="n">ones</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">mask_diag</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">band_part</span><span class="p">(</span><span class="n">ones</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="c1"># lower triangle removing the diagonal elements</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask_lower</span> <span class="o">-</span> <span class="n">mask_diag</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_tf</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mask</span>


<span class="k">def</span> <span class="nf">__get_dimensions__</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;计算相关维度长度.</span>

<span class="sd">    Notes:</span>
<span class="sd">        compute output shapes</span>

<span class="sd">    Args:</span>
<span class="sd">        input_shape: pass the inputs of layer to the function</span>
<span class="sd">        stride (int): the stride of the custom layer</span>

<span class="sd">    Returns:</span>
<span class="sd">        (features, output_length)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">int</span> <span class="ow">or</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be an integer &quot;</span>
                         <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
    <span class="n">time_steps</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">output_length</span> <span class="o">=</span> <span class="n">time_steps</span> <span class="o">//</span> <span class="n">stride</span>

    <span class="k">if</span> <span class="n">time_steps</span> <span class="o">%</span> <span class="n">stride</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Error, time_steps 应该是 stride的整数倍&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">features</span><span class="p">,</span> <span class="n">output_length</span>
</pre></div>

        </details>

            </section>
                <section id="Std">
                                <div class="attr class">
        <a class="headerlink" href="#Std">#&nbsp;&nbsp</a>

        
        <span class="def">class</span>
        <span class="name">Std</span><wbr>(<span class="base">tensorflow.python.keras.engine.base_layer.Layer</span>):
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Std</span><span class="p">(</span><span class="n">_Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;每个序列各个stride的标准差.</span>

<span class="sd">    Notes:</span>
<span class="sd">        计算每个feature各个stride的standard deviation</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;标准差.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Std</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;构建该层，计算维度信息.&quot;&quot;&quot;</span>
        <span class="p">(</span><span class="n">features</span><span class="p">,</span>
         <span class="n">output_length</span><span class="p">)</span> <span class="o">=</span> <span class="n">__get_dimensions__</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                   <span class="n">output_length</span><span class="p">,</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                   <span class="n">features</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride, features)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute means for each stride</span>
        <span class="n">means</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
            <span class="n">_tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                            <span class="n">ksize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                            <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>

        <span class="c1"># subtract means for each stride</span>
        <span class="n">squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">_tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">means</span><span class="p">))</span>
        <span class="n">squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">squared_diff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">)</span>

        <span class="c1"># compute standard deviation for each stride</span>
        <span class="n">mean_squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">squared_diff</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_diff</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">std</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>
</pre></div>

        </details>

            <div class="docstring"><p>每个序列各个stride的标准差.</p>

<h6 id="notes">Notes</h6>

<blockquote>
  <p>计算每个feature各个stride的standard deviation</p>
</blockquote>
</div>


                            <div id="Std.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Std.__init__">#&nbsp;&nbsp</a>

        
            <span class="name">Std</span><span class="signature">(stride: int = 10, **kwargs)</span>
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;标准差.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Std</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>

        </details>

            <div class="docstring"><p>标准差.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>stride (int):</strong>  time steps需要是stride的整数倍</li>
</ul>
</div>


                            </div>
                            <div id="Std.build" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Std.build">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">build</span><span class="signature">(self, input_shape)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;构建该层，计算维度信息.&quot;&quot;&quot;</span>
        <span class="p">(</span><span class="n">features</span><span class="p">,</span>
         <span class="n">output_length</span><span class="p">)</span> <span class="o">=</span> <span class="n">__get_dimensions__</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                   <span class="n">output_length</span><span class="p">,</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                   <span class="n">features</span><span class="p">]</span>
</pre></div>

        </details>

            <div class="docstring"><p>构建该层，计算维度信息.</p>
</div>


                            </div>
                            <div id="Std.call" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Std.call">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">call</span><span class="signature">(self, inputs, *args, **kwargs)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride, features)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute means for each stride</span>
        <span class="n">means</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
            <span class="n">_tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                            <span class="n">ksize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                            <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>

        <span class="c1"># subtract means for each stride</span>
        <span class="n">squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">_tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">means</span><span class="p">))</span>
        <span class="n">squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">squared_diff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">)</span>

        <span class="c1"># compute standard deviation for each stride</span>
        <span class="n">mean_squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">squared_diff</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_diff</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">std</span>
</pre></div>

        </details>

            <div class="docstring"><p>函数主逻辑实现部分.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>inputs (tensor):</strong>  输入dimension为(batch_size, time_steps, features)</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>dimension 为(batch_size, time_steps / stride, features)</p>
</blockquote>
</div>


                            </div>
                            <div id="Std.get_config" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Std.get_config">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">get_config</span><span class="signature">(self)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>
</pre></div>

        </details>

            <div class="docstring"><p>获取参数，保存模型需要的函数.</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>tensorflow.python.keras.engine.base_layer.Layer</dt>
                                <dd id="Std.add_weight" class="function">add_weight</dd>
                <dd id="Std.from_config" class="function">from_config</dd>
                <dd id="Std.compute_output_shape" class="function">compute_output_shape</dd>
                <dd id="Std.compute_output_signature" class="function">compute_output_signature</dd>
                <dd id="Std.compute_mask" class="function">compute_mask</dd>
                <dd id="Std.dtype" class="variable">dtype</dd>
                <dd id="Std.name" class="variable">name</dd>
                <dd id="Std.supports_masking" class="variable">supports_masking</dd>
                <dd id="Std.dynamic" class="variable">dynamic</dd>
                <dd id="Std.stateful" class="variable">stateful</dd>
                <dd id="Std.trainable" class="variable">trainable</dd>
                <dd id="Std.activity_regularizer" class="variable">activity_regularizer</dd>
                <dd id="Std.input_spec" class="variable">input_spec</dd>
                <dd id="Std.trainable_weights" class="variable">trainable_weights</dd>
                <dd id="Std.non_trainable_weights" class="variable">non_trainable_weights</dd>
                <dd id="Std.weights" class="variable">weights</dd>
                <dd id="Std.updates" class="variable">updates</dd>
                <dd id="Std.losses" class="variable">losses</dd>
                <dd id="Std.add_loss" class="function">add_loss</dd>
                <dd id="Std.metrics" class="variable">metrics</dd>
                <dd id="Std.add_metric" class="function">add_metric</dd>
                <dd id="Std.add_update" class="function">add_update</dd>
                <dd id="Std.set_weights" class="function">set_weights</dd>
                <dd id="Std.get_weights" class="function">get_weights</dd>
                <dd id="Std.get_updates_for" class="function">get_updates_for</dd>
                <dd id="Std.get_losses_for" class="function">get_losses_for</dd>
                <dd id="Std.get_input_mask_at" class="function">get_input_mask_at</dd>
                <dd id="Std.get_output_mask_at" class="function">get_output_mask_at</dd>
                <dd id="Std.input_mask" class="variable">input_mask</dd>
                <dd id="Std.output_mask" class="variable">output_mask</dd>
                <dd id="Std.get_input_shape_at" class="function">get_input_shape_at</dd>
                <dd id="Std.get_output_shape_at" class="function">get_output_shape_at</dd>
                <dd id="Std.get_input_at" class="function">get_input_at</dd>
                <dd id="Std.get_output_at" class="function">get_output_at</dd>
                <dd id="Std.input" class="variable">input</dd>
                <dd id="Std.output" class="variable">output</dd>
                <dd id="Std.input_shape" class="variable">input_shape</dd>
                <dd id="Std.count_params" class="function">count_params</dd>
                <dd id="Std.output_shape" class="variable">output_shape</dd>
                <dd id="Std.inbound_nodes" class="variable">inbound_nodes</dd>
                <dd id="Std.outbound_nodes" class="variable">outbound_nodes</dd>
                <dd id="Std.apply" class="function">apply</dd>
                <dd id="Std.add_variable" class="function">add_variable</dd>
                <dd id="Std.variables" class="variable">variables</dd>
                <dd id="Std.trainable_variables" class="variable">trainable_variables</dd>
                <dd id="Std.non_trainable_variables" class="variable">non_trainable_variables</dd>
                <dd id="Std.dtype_policy" class="variable">dtype_policy</dd>
                <dd id="Std.compute_dtype" class="variable">compute_dtype</dd>
                <dd id="Std.variable_dtype" class="variable">variable_dtype</dd>

            </div>
            <div><dt>tensorflow.python.module.module.Module</dt>
                                <dd id="Std.name_scope" class="variable">name_scope</dd>
                <dd id="Std.submodules" class="variable">submodules</dd>
                <dd id="Std.with_name_scope" class="function">with_name_scope</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="Return">
                                <div class="attr class">
        <a class="headerlink" href="#Return">#&nbsp;&nbsp</a>

        
        <span class="def">class</span>
        <span class="name">Return</span><wbr>(<span class="base">tensorflow.python.keras.engine.base_layer.Layer</span>):
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Return</span><span class="p">(</span><span class="n">_Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;每个序列各个stride的回报率.</span>

<span class="sd">    Notes:</span>
<span class="sd">        计算公式为每个stride最后一个数除以第一个数再减去一</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;回报率.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Return</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;构建该层，计算维度信息.&quot;&quot;&quot;</span>
        <span class="n">time_steps</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">time_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Error, time_steps 应该是 stride的整数倍&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride, features)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># get the endings of each strides as numerators</span>
        <span class="n">numerators</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)::</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="p">:]</span>

        <span class="c1"># get the beginnings of each strides as denominators</span>
        <span class="n">denominators</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="p">:]</span>

        <span class="k">return</span> <span class="n">_tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">divide_no_nan</span><span class="p">(</span><span class="n">numerators</span><span class="p">,</span> <span class="n">denominators</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.0</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>
</pre></div>

        </details>

            <div class="docstring"><p>每个序列各个stride的回报率.</p>

<h6 id="notes">Notes</h6>

<blockquote>
  <p>计算公式为每个stride最后一个数除以第一个数再减去一</p>
</blockquote>
</div>


                            <div id="Return.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Return.__init__">#&nbsp;&nbsp</a>

        
            <span class="name">Return</span><span class="signature">(stride=10, **kwargs)</span>
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;回报率.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Return</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
</pre></div>

        </details>

            <div class="docstring"><p>回报率.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>stride (int):</strong>  time steps需要是stride的整数倍</li>
</ul>
</div>


                            </div>
                            <div id="Return.build" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Return.build">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">build</span><span class="signature">(self, input_shape)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;构建该层，计算维度信息.&quot;&quot;&quot;</span>
        <span class="n">time_steps</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">time_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Error, time_steps 应该是 stride的整数倍&quot;</span><span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>构建该层，计算维度信息.</p>
</div>


                            </div>
                            <div id="Return.call" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Return.call">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">call</span><span class="signature">(self, inputs, *args, **kwargs)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride, features)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># get the endings of each strides as numerators</span>
        <span class="n">numerators</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)::</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="p">:]</span>

        <span class="c1"># get the beginnings of each strides as denominators</span>
        <span class="n">denominators</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="p">:]</span>

        <span class="k">return</span> <span class="n">_tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">divide_no_nan</span><span class="p">(</span><span class="n">numerators</span><span class="p">,</span> <span class="n">denominators</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.0</span>
</pre></div>

        </details>

            <div class="docstring"><p>函数主逻辑实现部分.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>inputs (tensor):</strong>  输入dimension为(batch_size, time_steps, features)</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>dimension 为(batch_size, time_steps / stride, features)</p>
</blockquote>
</div>


                            </div>
                            <div id="Return.get_config" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Return.get_config">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">get_config</span><span class="signature">(self)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>
</pre></div>

        </details>

            <div class="docstring"><p>获取参数，保存模型需要的函数.</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>tensorflow.python.keras.engine.base_layer.Layer</dt>
                                <dd id="Return.add_weight" class="function">add_weight</dd>
                <dd id="Return.from_config" class="function">from_config</dd>
                <dd id="Return.compute_output_shape" class="function">compute_output_shape</dd>
                <dd id="Return.compute_output_signature" class="function">compute_output_signature</dd>
                <dd id="Return.compute_mask" class="function">compute_mask</dd>
                <dd id="Return.dtype" class="variable">dtype</dd>
                <dd id="Return.name" class="variable">name</dd>
                <dd id="Return.supports_masking" class="variable">supports_masking</dd>
                <dd id="Return.dynamic" class="variable">dynamic</dd>
                <dd id="Return.stateful" class="variable">stateful</dd>
                <dd id="Return.trainable" class="variable">trainable</dd>
                <dd id="Return.activity_regularizer" class="variable">activity_regularizer</dd>
                <dd id="Return.input_spec" class="variable">input_spec</dd>
                <dd id="Return.trainable_weights" class="variable">trainable_weights</dd>
                <dd id="Return.non_trainable_weights" class="variable">non_trainable_weights</dd>
                <dd id="Return.weights" class="variable">weights</dd>
                <dd id="Return.updates" class="variable">updates</dd>
                <dd id="Return.losses" class="variable">losses</dd>
                <dd id="Return.add_loss" class="function">add_loss</dd>
                <dd id="Return.metrics" class="variable">metrics</dd>
                <dd id="Return.add_metric" class="function">add_metric</dd>
                <dd id="Return.add_update" class="function">add_update</dd>
                <dd id="Return.set_weights" class="function">set_weights</dd>
                <dd id="Return.get_weights" class="function">get_weights</dd>
                <dd id="Return.get_updates_for" class="function">get_updates_for</dd>
                <dd id="Return.get_losses_for" class="function">get_losses_for</dd>
                <dd id="Return.get_input_mask_at" class="function">get_input_mask_at</dd>
                <dd id="Return.get_output_mask_at" class="function">get_output_mask_at</dd>
                <dd id="Return.input_mask" class="variable">input_mask</dd>
                <dd id="Return.output_mask" class="variable">output_mask</dd>
                <dd id="Return.get_input_shape_at" class="function">get_input_shape_at</dd>
                <dd id="Return.get_output_shape_at" class="function">get_output_shape_at</dd>
                <dd id="Return.get_input_at" class="function">get_input_at</dd>
                <dd id="Return.get_output_at" class="function">get_output_at</dd>
                <dd id="Return.input" class="variable">input</dd>
                <dd id="Return.output" class="variable">output</dd>
                <dd id="Return.input_shape" class="variable">input_shape</dd>
                <dd id="Return.count_params" class="function">count_params</dd>
                <dd id="Return.output_shape" class="variable">output_shape</dd>
                <dd id="Return.inbound_nodes" class="variable">inbound_nodes</dd>
                <dd id="Return.outbound_nodes" class="variable">outbound_nodes</dd>
                <dd id="Return.apply" class="function">apply</dd>
                <dd id="Return.add_variable" class="function">add_variable</dd>
                <dd id="Return.variables" class="variable">variables</dd>
                <dd id="Return.trainable_variables" class="variable">trainable_variables</dd>
                <dd id="Return.non_trainable_variables" class="variable">non_trainable_variables</dd>
                <dd id="Return.dtype_policy" class="variable">dtype_policy</dd>
                <dd id="Return.compute_dtype" class="variable">compute_dtype</dd>
                <dd id="Return.variable_dtype" class="variable">variable_dtype</dd>

            </div>
            <div><dt>tensorflow.python.module.module.Module</dt>
                                <dd id="Return.name_scope" class="variable">name_scope</dd>
                <dd id="Return.submodules" class="variable">submodules</dd>
                <dd id="Return.with_name_scope" class="function">with_name_scope</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="Correlation">
                                <div class="attr class">
        <a class="headerlink" href="#Correlation">#&nbsp;&nbsp</a>

        
        <span class="def">class</span>
        <span class="name">Correlation</span><wbr>(<span class="base"><a href="#_OuterProductLayer">_OuterProductLayer</a></span>):
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Correlation</span><span class="p">(</span><span class="n">_OuterProductLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;每个stride各个时间序列的相关系数.</span>

<span class="sd">    Notes:</span>
<span class="sd">        计算每个stride每两个feature之间的correlation coefficient，</span>
<span class="sd">        输出feature数量为features * (features - 1) / 2</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride,</span>
<span class="sd">            features * (features - 1) / 2)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute means for each stride</span>
        <span class="n">means</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                <span class="n">ksize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">)</span>

        <span class="c1"># subtract means for each stride</span>
        <span class="n">means_broadcast</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">means_subtracted</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">means_broadcast</span><span class="p">)</span>
        <span class="n">means_subtracted</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">means_subtracted</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">)</span>

        <span class="c1"># compute standard deviations for each strides</span>
        <span class="n">squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">means_subtracted</span><span class="p">)</span>
        <span class="n">mean_squared_error</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">squared_diff</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">)</span>

        <span class="c1"># get denominator of correlation matrix</span>
        <span class="n">denominator_matrix</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ik,im-&gt;ikm&quot;</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>

        <span class="c1"># compute covariance matrix</span>
        <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ijk,ijm-&gt;ikm&quot;</span><span class="p">,</span>
                                       <span class="n">means_subtracted</span><span class="p">,</span>
                                       <span class="n">means_subtracted</span><span class="p">)</span>
        <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">covariance_matrix</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span>

        <span class="c1"># take the lower triangle of each matrix without diagonal</span>
        <span class="n">covariances</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">covariance_matrix</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">lower_mask</span><span class="p">,</span>
                                       <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">denominators</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">denominator_matrix</span><span class="p">,</span>
                                        <span class="bp">self</span><span class="o">.</span><span class="n">lower_mask</span><span class="p">,</span>
                                        <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">correlations</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">divide_no_nan</span><span class="p">(</span><span class="n">covariances</span><span class="p">,</span> <span class="n">denominators</span><span class="p">)</span>
        <span class="n">correlations</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">correlations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">correlations</span>
</pre></div>

        </details>

            <div class="docstring"><p>每个stride各个时间序列的相关系数.</p>

<h6 id="notes">Notes</h6>

<blockquote>
  <p>计算每个stride每两个feature之间的correlation coefficient，
  输出feature数量为features * (features - 1) / 2</p>
</blockquote>
</div>


                            <div id="Correlation.call" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Correlation.call">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">call</span><span class="signature">(self, inputs, *args, **kwargs)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride,</span>
<span class="sd">            features * (features - 1) / 2)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute means for each stride</span>
        <span class="n">means</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                <span class="n">ksize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">)</span>

        <span class="c1"># subtract means for each stride</span>
        <span class="n">means_broadcast</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">means_subtracted</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">means_broadcast</span><span class="p">)</span>
        <span class="n">means_subtracted</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">means_subtracted</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">)</span>

        <span class="c1"># compute standard deviations for each strides</span>
        <span class="n">squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">means_subtracted</span><span class="p">)</span>
        <span class="n">mean_squared_error</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">squared_diff</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">)</span>

        <span class="c1"># get denominator of correlation matrix</span>
        <span class="n">denominator_matrix</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ik,im-&gt;ikm&quot;</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>

        <span class="c1"># compute covariance matrix</span>
        <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ijk,ijm-&gt;ikm&quot;</span><span class="p">,</span>
                                       <span class="n">means_subtracted</span><span class="p">,</span>
                                       <span class="n">means_subtracted</span><span class="p">)</span>
        <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">covariance_matrix</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span>

        <span class="c1"># take the lower triangle of each matrix without diagonal</span>
        <span class="n">covariances</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">covariance_matrix</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">lower_mask</span><span class="p">,</span>
                                       <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">denominators</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">denominator_matrix</span><span class="p">,</span>
                                        <span class="bp">self</span><span class="o">.</span><span class="n">lower_mask</span><span class="p">,</span>
                                        <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">correlations</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">divide_no_nan</span><span class="p">(</span><span class="n">covariances</span><span class="p">,</span> <span class="n">denominators</span><span class="p">)</span>
        <span class="n">correlations</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">correlations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">correlations</span>
</pre></div>

        </details>

            <div class="docstring"><p>函数主逻辑实现部分.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>inputs (tensor):</strong>  输入dimension为(batch_size, time_steps, features)</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>dimension 为(batch_size, time_steps / stride,
  features * (features - 1) / 2)</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#_OuterProductLayer">_OuterProductLayer</a></dt>
                                <dd id="Correlation.__init__" class="function"><a href="#_OuterProductLayer.__init__">_OuterProductLayer</a></dd>
                <dd id="Correlation.build" class="function"><a href="#_OuterProductLayer.build">build</a></dd>
                <dd id="Correlation.get_config" class="function"><a href="#_OuterProductLayer.get_config">get_config</a></dd>

            </div>
            <div><dt>tensorflow.python.keras.engine.base_layer.Layer</dt>
                                <dd id="Correlation.add_weight" class="function">add_weight</dd>
                <dd id="Correlation.from_config" class="function">from_config</dd>
                <dd id="Correlation.compute_output_shape" class="function">compute_output_shape</dd>
                <dd id="Correlation.compute_output_signature" class="function">compute_output_signature</dd>
                <dd id="Correlation.compute_mask" class="function">compute_mask</dd>
                <dd id="Correlation.dtype" class="variable">dtype</dd>
                <dd id="Correlation.name" class="variable">name</dd>
                <dd id="Correlation.supports_masking" class="variable">supports_masking</dd>
                <dd id="Correlation.dynamic" class="variable">dynamic</dd>
                <dd id="Correlation.stateful" class="variable">stateful</dd>
                <dd id="Correlation.trainable" class="variable">trainable</dd>
                <dd id="Correlation.activity_regularizer" class="variable">activity_regularizer</dd>
                <dd id="Correlation.input_spec" class="variable">input_spec</dd>
                <dd id="Correlation.trainable_weights" class="variable">trainable_weights</dd>
                <dd id="Correlation.non_trainable_weights" class="variable">non_trainable_weights</dd>
                <dd id="Correlation.weights" class="variable">weights</dd>
                <dd id="Correlation.updates" class="variable">updates</dd>
                <dd id="Correlation.losses" class="variable">losses</dd>
                <dd id="Correlation.add_loss" class="function">add_loss</dd>
                <dd id="Correlation.metrics" class="variable">metrics</dd>
                <dd id="Correlation.add_metric" class="function">add_metric</dd>
                <dd id="Correlation.add_update" class="function">add_update</dd>
                <dd id="Correlation.set_weights" class="function">set_weights</dd>
                <dd id="Correlation.get_weights" class="function">get_weights</dd>
                <dd id="Correlation.get_updates_for" class="function">get_updates_for</dd>
                <dd id="Correlation.get_losses_for" class="function">get_losses_for</dd>
                <dd id="Correlation.get_input_mask_at" class="function">get_input_mask_at</dd>
                <dd id="Correlation.get_output_mask_at" class="function">get_output_mask_at</dd>
                <dd id="Correlation.input_mask" class="variable">input_mask</dd>
                <dd id="Correlation.output_mask" class="variable">output_mask</dd>
                <dd id="Correlation.get_input_shape_at" class="function">get_input_shape_at</dd>
                <dd id="Correlation.get_output_shape_at" class="function">get_output_shape_at</dd>
                <dd id="Correlation.get_input_at" class="function">get_input_at</dd>
                <dd id="Correlation.get_output_at" class="function">get_output_at</dd>
                <dd id="Correlation.input" class="variable">input</dd>
                <dd id="Correlation.output" class="variable">output</dd>
                <dd id="Correlation.input_shape" class="variable">input_shape</dd>
                <dd id="Correlation.count_params" class="function">count_params</dd>
                <dd id="Correlation.output_shape" class="variable">output_shape</dd>
                <dd id="Correlation.inbound_nodes" class="variable">inbound_nodes</dd>
                <dd id="Correlation.outbound_nodes" class="variable">outbound_nodes</dd>
                <dd id="Correlation.apply" class="function">apply</dd>
                <dd id="Correlation.add_variable" class="function">add_variable</dd>
                <dd id="Correlation.variables" class="variable">variables</dd>
                <dd id="Correlation.trainable_variables" class="variable">trainable_variables</dd>
                <dd id="Correlation.non_trainable_variables" class="variable">non_trainable_variables</dd>
                <dd id="Correlation.dtype_policy" class="variable">dtype_policy</dd>
                <dd id="Correlation.compute_dtype" class="variable">compute_dtype</dd>
                <dd id="Correlation.variable_dtype" class="variable">variable_dtype</dd>

            </div>
            <div><dt>tensorflow.python.module.module.Module</dt>
                                <dd id="Correlation.name_scope" class="variable">name_scope</dd>
                <dd id="Correlation.submodules" class="variable">submodules</dd>
                <dd id="Correlation.with_name_scope" class="function">with_name_scope</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="LinearDecay">
                                <div class="attr class">
        <a class="headerlink" href="#LinearDecay">#&nbsp;&nbsp</a>

        
        <span class="def">class</span>
        <span class="name">LinearDecay</span><wbr>(<span class="base">tensorflow.python.keras.engine.base_layer.Layer</span>):
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">LinearDecay</span><span class="p">(</span><span class="n">_Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;每个序列各个stride的线性衰减加权平均.</span>

<span class="sd">    Notes:</span>
<span class="sd">        以线性衰减为权重，计算每个feature各个stride的均值：</span>
<span class="sd">        如stride为10，则某feature该stride的权重为(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;线性递减加权平均.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearDecay</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;构建该层，计算维度信息.&quot;&quot;&quot;</span>
        <span class="p">(</span><span class="n">features</span><span class="p">,</span>
         <span class="n">output_length</span><span class="p">)</span> <span class="o">=</span> <span class="n">__get_dimensions__</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_length</span><span class="p">,</span> <span class="n">features</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">features</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride, features)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># get linear decay kernel</span>
        <span class="n">single_kernel</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">single_kernel</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span> <span class="o">/</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">single_kernel</span><span class="p">)</span>

        <span class="c1"># reshape tensors into:</span>
        <span class="c1"># (bash_size * (time_steps / stride), stride, features)</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">)</span>

        <span class="c1"># broadcasting kernel to inputs batch dimension</span>
        <span class="n">linear_decay</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">kernel</span> <span class="o">*</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">linear_decay</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">linear_decay</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">linear_decay</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>
</pre></div>

        </details>

            <div class="docstring"><p>每个序列各个stride的线性衰减加权平均.</p>

<h6 id="notes">Notes</h6>

<blockquote>
  <p>以线性衰减为权重，计算每个feature各个stride的均值：
  如stride为10，则某feature该stride的权重为(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)</p>
</blockquote>
</div>


                            <div id="LinearDecay.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#LinearDecay.__init__">#&nbsp;&nbsp</a>

        
            <span class="name">LinearDecay</span><span class="signature">(stride=10, **kwargs)</span>
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;线性递减加权平均.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearDecay</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>

        </details>

            <div class="docstring"><p>线性递减加权平均.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>stride (int):</strong>  time steps需要是stride的整数倍</li>
</ul>
</div>


                            </div>
                            <div id="LinearDecay.build" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#LinearDecay.build">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">build</span><span class="signature">(self, input_shape)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;构建该层，计算维度信息.&quot;&quot;&quot;</span>
        <span class="p">(</span><span class="n">features</span><span class="p">,</span>
         <span class="n">output_length</span><span class="p">)</span> <span class="o">=</span> <span class="n">__get_dimensions__</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_length</span><span class="p">,</span> <span class="n">features</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">features</span><span class="p">]</span>
</pre></div>

        </details>

            <div class="docstring"><p>构建该层，计算维度信息.</p>
</div>


                            </div>
                            <div id="LinearDecay.call" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#LinearDecay.call">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">call</span><span class="signature">(self, inputs, *args, **kwargs)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride, features)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># get linear decay kernel</span>
        <span class="n">single_kernel</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">single_kernel</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span> <span class="o">/</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">single_kernel</span><span class="p">)</span>

        <span class="c1"># reshape tensors into:</span>
        <span class="c1"># (bash_size * (time_steps / stride), stride, features)</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">)</span>

        <span class="c1"># broadcasting kernel to inputs batch dimension</span>
        <span class="n">linear_decay</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">kernel</span> <span class="o">*</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">linear_decay</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">linear_decay</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">linear_decay</span>
</pre></div>

        </details>

            <div class="docstring"><p>函数主逻辑实现部分.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>inputs (tensor):</strong>  输入dimension为(batch_size, time_steps, features)</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>dimension 为(batch_size, time_steps / stride, features)</p>
</blockquote>
</div>


                            </div>
                            <div id="LinearDecay.get_config" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#LinearDecay.get_config">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">get_config</span><span class="signature">(self)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>
</pre></div>

        </details>

            <div class="docstring"><p>获取参数，保存模型需要的函数.</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>tensorflow.python.keras.engine.base_layer.Layer</dt>
                                <dd id="LinearDecay.add_weight" class="function">add_weight</dd>
                <dd id="LinearDecay.from_config" class="function">from_config</dd>
                <dd id="LinearDecay.compute_output_shape" class="function">compute_output_shape</dd>
                <dd id="LinearDecay.compute_output_signature" class="function">compute_output_signature</dd>
                <dd id="LinearDecay.compute_mask" class="function">compute_mask</dd>
                <dd id="LinearDecay.dtype" class="variable">dtype</dd>
                <dd id="LinearDecay.name" class="variable">name</dd>
                <dd id="LinearDecay.supports_masking" class="variable">supports_masking</dd>
                <dd id="LinearDecay.dynamic" class="variable">dynamic</dd>
                <dd id="LinearDecay.stateful" class="variable">stateful</dd>
                <dd id="LinearDecay.trainable" class="variable">trainable</dd>
                <dd id="LinearDecay.activity_regularizer" class="variable">activity_regularizer</dd>
                <dd id="LinearDecay.input_spec" class="variable">input_spec</dd>
                <dd id="LinearDecay.trainable_weights" class="variable">trainable_weights</dd>
                <dd id="LinearDecay.non_trainable_weights" class="variable">non_trainable_weights</dd>
                <dd id="LinearDecay.weights" class="variable">weights</dd>
                <dd id="LinearDecay.updates" class="variable">updates</dd>
                <dd id="LinearDecay.losses" class="variable">losses</dd>
                <dd id="LinearDecay.add_loss" class="function">add_loss</dd>
                <dd id="LinearDecay.metrics" class="variable">metrics</dd>
                <dd id="LinearDecay.add_metric" class="function">add_metric</dd>
                <dd id="LinearDecay.add_update" class="function">add_update</dd>
                <dd id="LinearDecay.set_weights" class="function">set_weights</dd>
                <dd id="LinearDecay.get_weights" class="function">get_weights</dd>
                <dd id="LinearDecay.get_updates_for" class="function">get_updates_for</dd>
                <dd id="LinearDecay.get_losses_for" class="function">get_losses_for</dd>
                <dd id="LinearDecay.get_input_mask_at" class="function">get_input_mask_at</dd>
                <dd id="LinearDecay.get_output_mask_at" class="function">get_output_mask_at</dd>
                <dd id="LinearDecay.input_mask" class="variable">input_mask</dd>
                <dd id="LinearDecay.output_mask" class="variable">output_mask</dd>
                <dd id="LinearDecay.get_input_shape_at" class="function">get_input_shape_at</dd>
                <dd id="LinearDecay.get_output_shape_at" class="function">get_output_shape_at</dd>
                <dd id="LinearDecay.get_input_at" class="function">get_input_at</dd>
                <dd id="LinearDecay.get_output_at" class="function">get_output_at</dd>
                <dd id="LinearDecay.input" class="variable">input</dd>
                <dd id="LinearDecay.output" class="variable">output</dd>
                <dd id="LinearDecay.input_shape" class="variable">input_shape</dd>
                <dd id="LinearDecay.count_params" class="function">count_params</dd>
                <dd id="LinearDecay.output_shape" class="variable">output_shape</dd>
                <dd id="LinearDecay.inbound_nodes" class="variable">inbound_nodes</dd>
                <dd id="LinearDecay.outbound_nodes" class="variable">outbound_nodes</dd>
                <dd id="LinearDecay.apply" class="function">apply</dd>
                <dd id="LinearDecay.add_variable" class="function">add_variable</dd>
                <dd id="LinearDecay.variables" class="variable">variables</dd>
                <dd id="LinearDecay.trainable_variables" class="variable">trainable_variables</dd>
                <dd id="LinearDecay.non_trainable_variables" class="variable">non_trainable_variables</dd>
                <dd id="LinearDecay.dtype_policy" class="variable">dtype_policy</dd>
                <dd id="LinearDecay.compute_dtype" class="variable">compute_dtype</dd>
                <dd id="LinearDecay.variable_dtype" class="variable">variable_dtype</dd>

            </div>
            <div><dt>tensorflow.python.module.module.Module</dt>
                                <dd id="LinearDecay.name_scope" class="variable">name_scope</dd>
                <dd id="LinearDecay.submodules" class="variable">submodules</dd>
                <dd id="LinearDecay.with_name_scope" class="function">with_name_scope</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="Covariance">
                                <div class="attr class">
        <a class="headerlink" href="#Covariance">#&nbsp;&nbsp</a>

        
        <span class="def">class</span>
        <span class="name">Covariance</span><wbr>(<span class="base"><a href="#_OuterProductLayer">_OuterProductLayer</a></span>):
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Covariance</span><span class="p">(</span><span class="n">_OuterProductLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;每个stride各个时间序列的covariance.</span>

<span class="sd">    Notes:</span>
<span class="sd">        计算每个stride每两个feature之间的covariance大小，</span>
<span class="sd">        输出feature数量为features * (features - 1) / 2</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride,</span>
<span class="sd">            features * (features - 1) / 2)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute means for each stride</span>
        <span class="n">means</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                <span class="n">ksize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">)</span>

        <span class="c1"># subtract means for each stride</span>
        <span class="n">means_broadcast</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">means_subtracted</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">means_broadcast</span><span class="p">)</span>
        <span class="n">means_subtracted</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">means_subtracted</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">)</span>

        <span class="c1"># compute covariance matrix</span>
        <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ijk,ijm-&gt;ikm&quot;</span><span class="p">,</span>
                                       <span class="n">means_subtracted</span><span class="p">,</span>
                                       <span class="n">means_subtracted</span><span class="p">)</span>
        <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">covariance_matrix</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># get the lower part of the covariance matrix</span>
        <span class="c1"># without the diagonal elements</span>
        <span class="n">covariances</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">covariance_matrix</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">lower_mask</span><span class="p">,</span>
                                       <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">covariances</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">covariances</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">covariances</span>
</pre></div>

        </details>

            <div class="docstring"><p>每个stride各个时间序列的covariance.</p>

<h6 id="notes">Notes</h6>

<blockquote>
  <p>计算每个stride每两个feature之间的covariance大小，
  输出feature数量为features * (features - 1) / 2</p>
</blockquote>
</div>


                            <div id="Covariance.call" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Covariance.call">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">call</span><span class="signature">(self, inputs, *args, **kwargs)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride,</span>
<span class="sd">            features * (features - 1) / 2)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute means for each stride</span>
        <span class="n">means</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                <span class="n">ksize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">)</span>

        <span class="c1"># subtract means for each stride</span>
        <span class="n">means_broadcast</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">means_subtracted</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">means_broadcast</span><span class="p">)</span>
        <span class="n">means_subtracted</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">means_subtracted</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">)</span>

        <span class="c1"># compute covariance matrix</span>
        <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ijk,ijm-&gt;ikm&quot;</span><span class="p">,</span>
                                       <span class="n">means_subtracted</span><span class="p">,</span>
                                       <span class="n">means_subtracted</span><span class="p">)</span>
        <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">covariance_matrix</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># get the lower part of the covariance matrix</span>
        <span class="c1"># without the diagonal elements</span>
        <span class="n">covariances</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">covariance_matrix</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">lower_mask</span><span class="p">,</span>
                                       <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">covariances</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">covariances</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">covariances</span>
</pre></div>

        </details>

            <div class="docstring"><p>函数主逻辑实现部分.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>inputs (tensor):</strong>  输入dimension为(batch_size, time_steps, features)</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>dimension 为(batch_size, time_steps / stride,
  features * (features - 1) / 2)</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#_OuterProductLayer">_OuterProductLayer</a></dt>
                                <dd id="Covariance.__init__" class="function"><a href="#_OuterProductLayer.__init__">_OuterProductLayer</a></dd>
                <dd id="Covariance.build" class="function"><a href="#_OuterProductLayer.build">build</a></dd>
                <dd id="Covariance.get_config" class="function"><a href="#_OuterProductLayer.get_config">get_config</a></dd>

            </div>
            <div><dt>tensorflow.python.keras.engine.base_layer.Layer</dt>
                                <dd id="Covariance.add_weight" class="function">add_weight</dd>
                <dd id="Covariance.from_config" class="function">from_config</dd>
                <dd id="Covariance.compute_output_shape" class="function">compute_output_shape</dd>
                <dd id="Covariance.compute_output_signature" class="function">compute_output_signature</dd>
                <dd id="Covariance.compute_mask" class="function">compute_mask</dd>
                <dd id="Covariance.dtype" class="variable">dtype</dd>
                <dd id="Covariance.name" class="variable">name</dd>
                <dd id="Covariance.supports_masking" class="variable">supports_masking</dd>
                <dd id="Covariance.dynamic" class="variable">dynamic</dd>
                <dd id="Covariance.stateful" class="variable">stateful</dd>
                <dd id="Covariance.trainable" class="variable">trainable</dd>
                <dd id="Covariance.activity_regularizer" class="variable">activity_regularizer</dd>
                <dd id="Covariance.input_spec" class="variable">input_spec</dd>
                <dd id="Covariance.trainable_weights" class="variable">trainable_weights</dd>
                <dd id="Covariance.non_trainable_weights" class="variable">non_trainable_weights</dd>
                <dd id="Covariance.weights" class="variable">weights</dd>
                <dd id="Covariance.updates" class="variable">updates</dd>
                <dd id="Covariance.losses" class="variable">losses</dd>
                <dd id="Covariance.add_loss" class="function">add_loss</dd>
                <dd id="Covariance.metrics" class="variable">metrics</dd>
                <dd id="Covariance.add_metric" class="function">add_metric</dd>
                <dd id="Covariance.add_update" class="function">add_update</dd>
                <dd id="Covariance.set_weights" class="function">set_weights</dd>
                <dd id="Covariance.get_weights" class="function">get_weights</dd>
                <dd id="Covariance.get_updates_for" class="function">get_updates_for</dd>
                <dd id="Covariance.get_losses_for" class="function">get_losses_for</dd>
                <dd id="Covariance.get_input_mask_at" class="function">get_input_mask_at</dd>
                <dd id="Covariance.get_output_mask_at" class="function">get_output_mask_at</dd>
                <dd id="Covariance.input_mask" class="variable">input_mask</dd>
                <dd id="Covariance.output_mask" class="variable">output_mask</dd>
                <dd id="Covariance.get_input_shape_at" class="function">get_input_shape_at</dd>
                <dd id="Covariance.get_output_shape_at" class="function">get_output_shape_at</dd>
                <dd id="Covariance.get_input_at" class="function">get_input_at</dd>
                <dd id="Covariance.get_output_at" class="function">get_output_at</dd>
                <dd id="Covariance.input" class="variable">input</dd>
                <dd id="Covariance.output" class="variable">output</dd>
                <dd id="Covariance.input_shape" class="variable">input_shape</dd>
                <dd id="Covariance.count_params" class="function">count_params</dd>
                <dd id="Covariance.output_shape" class="variable">output_shape</dd>
                <dd id="Covariance.inbound_nodes" class="variable">inbound_nodes</dd>
                <dd id="Covariance.outbound_nodes" class="variable">outbound_nodes</dd>
                <dd id="Covariance.apply" class="function">apply</dd>
                <dd id="Covariance.add_variable" class="function">add_variable</dd>
                <dd id="Covariance.variables" class="variable">variables</dd>
                <dd id="Covariance.trainable_variables" class="variable">trainable_variables</dd>
                <dd id="Covariance.non_trainable_variables" class="variable">non_trainable_variables</dd>
                <dd id="Covariance.dtype_policy" class="variable">dtype_policy</dd>
                <dd id="Covariance.compute_dtype" class="variable">compute_dtype</dd>
                <dd id="Covariance.variable_dtype" class="variable">variable_dtype</dd>

            </div>
            <div><dt>tensorflow.python.module.module.Module</dt>
                                <dd id="Covariance.name_scope" class="variable">name_scope</dd>
                <dd id="Covariance.submodules" class="variable">submodules</dd>
                <dd id="Covariance.with_name_scope" class="function">with_name_scope</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ZScore">
                                <div class="attr class">
        <a class="headerlink" href="#ZScore">#&nbsp;&nbsp</a>

        
        <span class="def">class</span>
        <span class="name">ZScore</span><wbr>(<span class="base">tensorflow.python.keras.engine.base_layer.Layer</span>):
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">ZScore</span><span class="p">(</span><span class="n">_Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;每个序列各个stride的均值除以其标准差.</span>

<span class="sd">    Notes:</span>
<span class="sd">        并非严格意义上的z-score,</span>
<span class="sd">        计算公式为每个feature各个stride的mean除以各自的standard deviation</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;均值除以标准差.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ZScore</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;构建该层，计算维度信息.&quot;&quot;&quot;</span>
        <span class="p">(</span><span class="n">features</span><span class="p">,</span>
         <span class="n">output_length</span><span class="p">)</span> <span class="o">=</span> <span class="n">__get_dimensions__</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                   <span class="n">output_length</span><span class="p">,</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                   <span class="n">features</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride, features)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute means for each stride</span>
        <span class="n">means</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                <span class="n">ksize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">)</span>

        <span class="c1"># compute standard deviations for each stride</span>
        <span class="n">means_broadcast</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">_tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">means_broadcast</span><span class="p">))</span>
        <span class="n">squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">squared_diff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">)</span>
        <span class="n">mean_squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">squared_diff</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_diff</span><span class="p">)</span>

        <span class="c1"># divide means by standard deviations for each stride</span>
        <span class="n">z_score</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">divide_no_nan</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z_score</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>
</pre></div>

        </details>

            <div class="docstring"><p>每个序列各个stride的均值除以其标准差.</p>

<h6 id="notes">Notes</h6>

<blockquote>
  <p>并非严格意义上的z-score,
  计算公式为每个feature各个stride的mean除以各自的standard deviation</p>
</blockquote>
</div>


                            <div id="ZScore.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#ZScore.__init__">#&nbsp;&nbsp</a>

        
            <span class="name">ZScore</span><span class="signature">(stride: int = 10, **kwargs)</span>
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;均值除以标准差.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ZScore</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>

        </details>

            <div class="docstring"><p>均值除以标准差.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>stride (int):</strong>  time steps需要是stride的整数倍</li>
</ul>
</div>


                            </div>
                            <div id="ZScore.build" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#ZScore.build">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">build</span><span class="signature">(self, input_shape)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;构建该层，计算维度信息.&quot;&quot;&quot;</span>
        <span class="p">(</span><span class="n">features</span><span class="p">,</span>
         <span class="n">output_length</span><span class="p">)</span> <span class="o">=</span> <span class="n">__get_dimensions__</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                   <span class="n">output_length</span><span class="p">,</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                   <span class="n">features</span><span class="p">]</span>
</pre></div>

        </details>

            <div class="docstring"><p>构建该层，计算维度信息.</p>
</div>


                            </div>
                            <div id="ZScore.call" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#ZScore.call">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">call</span><span class="signature">(self, inputs, *args, **kwargs)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride, features)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute means for each stride</span>
        <span class="n">means</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                <span class="n">ksize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">)</span>

        <span class="c1"># compute standard deviations for each stride</span>
        <span class="n">means_broadcast</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">_tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">means_broadcast</span><span class="p">))</span>
        <span class="n">squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">squared_diff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_shape</span><span class="p">)</span>
        <span class="n">mean_squared_diff</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">squared_diff</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_diff</span><span class="p">)</span>

        <span class="c1"># divide means by standard deviations for each stride</span>
        <span class="n">z_score</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">divide_no_nan</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z_score</span>
</pre></div>

        </details>

            <div class="docstring"><p>函数主逻辑实现部分.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>inputs (tensor):</strong>  输入dimension为(batch_size, time_steps, features)</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>dimension 为(batch_size, time_steps / stride, features)</p>
</blockquote>
</div>


                            </div>
                            <div id="ZScore.get_config" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#ZScore.get_config">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">get_config</span><span class="signature">(self)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>
</pre></div>

        </details>

            <div class="docstring"><p>获取参数，保存模型需要的函数.</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>tensorflow.python.keras.engine.base_layer.Layer</dt>
                                <dd id="ZScore.add_weight" class="function">add_weight</dd>
                <dd id="ZScore.from_config" class="function">from_config</dd>
                <dd id="ZScore.compute_output_shape" class="function">compute_output_shape</dd>
                <dd id="ZScore.compute_output_signature" class="function">compute_output_signature</dd>
                <dd id="ZScore.compute_mask" class="function">compute_mask</dd>
                <dd id="ZScore.dtype" class="variable">dtype</dd>
                <dd id="ZScore.name" class="variable">name</dd>
                <dd id="ZScore.supports_masking" class="variable">supports_masking</dd>
                <dd id="ZScore.dynamic" class="variable">dynamic</dd>
                <dd id="ZScore.stateful" class="variable">stateful</dd>
                <dd id="ZScore.trainable" class="variable">trainable</dd>
                <dd id="ZScore.activity_regularizer" class="variable">activity_regularizer</dd>
                <dd id="ZScore.input_spec" class="variable">input_spec</dd>
                <dd id="ZScore.trainable_weights" class="variable">trainable_weights</dd>
                <dd id="ZScore.non_trainable_weights" class="variable">non_trainable_weights</dd>
                <dd id="ZScore.weights" class="variable">weights</dd>
                <dd id="ZScore.updates" class="variable">updates</dd>
                <dd id="ZScore.losses" class="variable">losses</dd>
                <dd id="ZScore.add_loss" class="function">add_loss</dd>
                <dd id="ZScore.metrics" class="variable">metrics</dd>
                <dd id="ZScore.add_metric" class="function">add_metric</dd>
                <dd id="ZScore.add_update" class="function">add_update</dd>
                <dd id="ZScore.set_weights" class="function">set_weights</dd>
                <dd id="ZScore.get_weights" class="function">get_weights</dd>
                <dd id="ZScore.get_updates_for" class="function">get_updates_for</dd>
                <dd id="ZScore.get_losses_for" class="function">get_losses_for</dd>
                <dd id="ZScore.get_input_mask_at" class="function">get_input_mask_at</dd>
                <dd id="ZScore.get_output_mask_at" class="function">get_output_mask_at</dd>
                <dd id="ZScore.input_mask" class="variable">input_mask</dd>
                <dd id="ZScore.output_mask" class="variable">output_mask</dd>
                <dd id="ZScore.get_input_shape_at" class="function">get_input_shape_at</dd>
                <dd id="ZScore.get_output_shape_at" class="function">get_output_shape_at</dd>
                <dd id="ZScore.get_input_at" class="function">get_input_at</dd>
                <dd id="ZScore.get_output_at" class="function">get_output_at</dd>
                <dd id="ZScore.input" class="variable">input</dd>
                <dd id="ZScore.output" class="variable">output</dd>
                <dd id="ZScore.input_shape" class="variable">input_shape</dd>
                <dd id="ZScore.count_params" class="function">count_params</dd>
                <dd id="ZScore.output_shape" class="variable">output_shape</dd>
                <dd id="ZScore.inbound_nodes" class="variable">inbound_nodes</dd>
                <dd id="ZScore.outbound_nodes" class="variable">outbound_nodes</dd>
                <dd id="ZScore.apply" class="function">apply</dd>
                <dd id="ZScore.add_variable" class="function">add_variable</dd>
                <dd id="ZScore.variables" class="variable">variables</dd>
                <dd id="ZScore.trainable_variables" class="variable">trainable_variables</dd>
                <dd id="ZScore.non_trainable_variables" class="variable">non_trainable_variables</dd>
                <dd id="ZScore.dtype_policy" class="variable">dtype_policy</dd>
                <dd id="ZScore.compute_dtype" class="variable">compute_dtype</dd>
                <dd id="ZScore.variable_dtype" class="variable">variable_dtype</dd>

            </div>
            <div><dt>tensorflow.python.module.module.Module</dt>
                                <dd id="ZScore.name_scope" class="variable">name_scope</dd>
                <dd id="ZScore.submodules" class="variable">submodules</dd>
                <dd id="ZScore.with_name_scope" class="function">with_name_scope</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="FeatureExpansion">
                                <div class="attr class">
        <a class="headerlink" href="#FeatureExpansion">#&nbsp;&nbsp</a>

        
        <span class="def">class</span>
        <span class="name">FeatureExpansion</span><wbr>(<span class="base">tensorflow.python.keras.engine.base_layer.Layer</span>):
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">FeatureExpansion</span><span class="p">(</span><span class="n">_Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;时间序列特征扩张层.</span>

<span class="sd">    Notes:</span>
<span class="sd">        该层扩张时间序列的feature数量，并通过stride缩短时间序列长度，</span>
<span class="sd">        其包括一下一些feature:</span>

<span class="sd">            - standard deviation</span>

<span class="sd">            - mean / standard deviation</span>

<span class="sd">            - linear decay average</span>

<span class="sd">            - return of each stride</span>

<span class="sd">            - covariance of each two features for each stride</span>

<span class="sd">            - correlation coefficient of each two features for each stride</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;时间序列特征扩张.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">int</span> <span class="ow">or</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be an integer &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FeatureExpansion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">Std</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z_score</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">ZScore</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_decay</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">LinearDecay</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">Return</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covariance</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">Covariance</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">Correlation</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride,</span>
<span class="sd">            features * (features + 3))</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">std_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">z_score_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">z_score</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">decay_linear_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_decay</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">return_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">covariance_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covariance</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">correlation_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">correlation</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">std_output</span><span class="p">,</span>
                           <span class="n">z_score_output</span><span class="p">,</span>
                           <span class="n">decay_linear_output</span><span class="p">,</span>
                           <span class="n">return_output</span><span class="p">,</span>
                           <span class="n">covariance_output</span><span class="p">,</span>
                           <span class="n">correlation_output</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>
</pre></div>

        </details>

            <div class="docstring"><p>时间序列特征扩张层.</p>

<h6 id="notes">Notes</h6>

<blockquote>
  <p>该层扩张时间序列的feature数量，并通过stride缩短时间序列长度，
  其包括一下一些feature:</p>

<pre><code>- standard deviation

- mean / standard deviation

- linear decay average

- return of each stride

- covariance of each two features for each stride

- correlation coefficient of each two features for each stride
</code></pre>
</blockquote>
</div>


                            <div id="FeatureExpansion.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FeatureExpansion.__init__">#&nbsp;&nbsp</a>

        
            <span class="name">FeatureExpansion</span><span class="signature">(stride=10, **kwargs)</span>
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;时间序列特征扩张.</span>

<span class="sd">        Args:</span>
<span class="sd">            stride (int): time steps需要是stride的整数倍</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">int</span> <span class="ow">or</span> <span class="n">stride</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal Argument: stride should be an integer &quot;</span>
                             <span class="s2">&quot;greater than 1&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FeatureExpansion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">Std</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z_score</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">ZScore</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_decay</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">LinearDecay</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">Return</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covariance</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">Covariance</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">Correlation</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">))</span>
</pre></div>

        </details>

            <div class="docstring"><p>时间序列特征扩张.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>stride (int):</strong>  time steps需要是stride的整数倍</li>
</ul>
</div>


                            </div>
                            <div id="FeatureExpansion.call" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FeatureExpansion.call">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">call</span><span class="signature">(self, inputs, *args, **kwargs)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;函数主逻辑实现部分.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (tensor): 输入dimension为(batch_size, time_steps, features)</span>

<span class="sd">        Returns:</span>
<span class="sd">            dimension 为(batch_size, time_steps / stride,</span>
<span class="sd">            features * (features + 3))</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">std_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">z_score_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">z_score</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">decay_linear_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_decay</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">return_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">covariance_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covariance</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">correlation_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">correlation</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">std_output</span><span class="p">,</span>
                           <span class="n">z_score_output</span><span class="p">,</span>
                           <span class="n">decay_linear_output</span><span class="p">,</span>
                           <span class="n">return_output</span><span class="p">,</span>
                           <span class="n">covariance_output</span><span class="p">,</span>
                           <span class="n">correlation_output</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>函数主逻辑实现部分.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>inputs (tensor):</strong>  输入dimension为(batch_size, time_steps, features)</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>dimension 为(batch_size, time_steps / stride,
  features * (features + 3))</p>
</blockquote>
</div>


                            </div>
                            <div id="FeatureExpansion.get_config" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FeatureExpansion.get_config">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">get_config</span><span class="signature">(self)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;stride&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>
</pre></div>

        </details>

            <div class="docstring"><p>获取参数，保存模型需要的函数.</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>tensorflow.python.keras.engine.base_layer.Layer</dt>
                                <dd id="FeatureExpansion.build" class="function">build</dd>
                <dd id="FeatureExpansion.add_weight" class="function">add_weight</dd>
                <dd id="FeatureExpansion.from_config" class="function">from_config</dd>
                <dd id="FeatureExpansion.compute_output_shape" class="function">compute_output_shape</dd>
                <dd id="FeatureExpansion.compute_output_signature" class="function">compute_output_signature</dd>
                <dd id="FeatureExpansion.compute_mask" class="function">compute_mask</dd>
                <dd id="FeatureExpansion.dtype" class="variable">dtype</dd>
                <dd id="FeatureExpansion.name" class="variable">name</dd>
                <dd id="FeatureExpansion.supports_masking" class="variable">supports_masking</dd>
                <dd id="FeatureExpansion.dynamic" class="variable">dynamic</dd>
                <dd id="FeatureExpansion.stateful" class="variable">stateful</dd>
                <dd id="FeatureExpansion.trainable" class="variable">trainable</dd>
                <dd id="FeatureExpansion.activity_regularizer" class="variable">activity_regularizer</dd>
                <dd id="FeatureExpansion.input_spec" class="variable">input_spec</dd>
                <dd id="FeatureExpansion.trainable_weights" class="variable">trainable_weights</dd>
                <dd id="FeatureExpansion.non_trainable_weights" class="variable">non_trainable_weights</dd>
                <dd id="FeatureExpansion.weights" class="variable">weights</dd>
                <dd id="FeatureExpansion.updates" class="variable">updates</dd>
                <dd id="FeatureExpansion.losses" class="variable">losses</dd>
                <dd id="FeatureExpansion.add_loss" class="function">add_loss</dd>
                <dd id="FeatureExpansion.metrics" class="variable">metrics</dd>
                <dd id="FeatureExpansion.add_metric" class="function">add_metric</dd>
                <dd id="FeatureExpansion.add_update" class="function">add_update</dd>
                <dd id="FeatureExpansion.set_weights" class="function">set_weights</dd>
                <dd id="FeatureExpansion.get_weights" class="function">get_weights</dd>
                <dd id="FeatureExpansion.get_updates_for" class="function">get_updates_for</dd>
                <dd id="FeatureExpansion.get_losses_for" class="function">get_losses_for</dd>
                <dd id="FeatureExpansion.get_input_mask_at" class="function">get_input_mask_at</dd>
                <dd id="FeatureExpansion.get_output_mask_at" class="function">get_output_mask_at</dd>
                <dd id="FeatureExpansion.input_mask" class="variable">input_mask</dd>
                <dd id="FeatureExpansion.output_mask" class="variable">output_mask</dd>
                <dd id="FeatureExpansion.get_input_shape_at" class="function">get_input_shape_at</dd>
                <dd id="FeatureExpansion.get_output_shape_at" class="function">get_output_shape_at</dd>
                <dd id="FeatureExpansion.get_input_at" class="function">get_input_at</dd>
                <dd id="FeatureExpansion.get_output_at" class="function">get_output_at</dd>
                <dd id="FeatureExpansion.input" class="variable">input</dd>
                <dd id="FeatureExpansion.output" class="variable">output</dd>
                <dd id="FeatureExpansion.input_shape" class="variable">input_shape</dd>
                <dd id="FeatureExpansion.count_params" class="function">count_params</dd>
                <dd id="FeatureExpansion.output_shape" class="variable">output_shape</dd>
                <dd id="FeatureExpansion.inbound_nodes" class="variable">inbound_nodes</dd>
                <dd id="FeatureExpansion.outbound_nodes" class="variable">outbound_nodes</dd>
                <dd id="FeatureExpansion.apply" class="function">apply</dd>
                <dd id="FeatureExpansion.add_variable" class="function">add_variable</dd>
                <dd id="FeatureExpansion.variables" class="variable">variables</dd>
                <dd id="FeatureExpansion.trainable_variables" class="variable">trainable_variables</dd>
                <dd id="FeatureExpansion.non_trainable_variables" class="variable">non_trainable_variables</dd>
                <dd id="FeatureExpansion.dtype_policy" class="variable">dtype_policy</dd>
                <dd id="FeatureExpansion.compute_dtype" class="variable">compute_dtype</dd>
                <dd id="FeatureExpansion.variable_dtype" class="variable">variable_dtype</dd>

            </div>
            <div><dt>tensorflow.python.module.module.Module</dt>
                                <dd id="FeatureExpansion.name_scope" class="variable">name_scope</dd>
                <dd id="FeatureExpansion.submodules" class="variable">submodules</dd>
                <dd id="FeatureExpansion.with_name_scope" class="function">with_name_scope</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="AlphaNetV3">
                                <div class="attr class">
        <a class="headerlink" href="#AlphaNetV3">#&nbsp;&nbsp</a>

        
        <span class="def">class</span>
        <span class="name">AlphaNetV3</span><wbr>(<span class="base">tensorflow.python.keras.engine.training.Model</span>):
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">AlphaNetV3</span><span class="p">(</span><span class="n">_Model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;alpha net v3版本模型.</span>

<span class="sd">    Notes:</span>
<span class="sd">        复现华泰金工 alpha net V3 版本</span>
<span class="sd">        ::</span>

<span class="sd">            input: (batch_size, history time steps, features)</span>

<span class="sd">                            stride = 5</span>
<span class="sd">                    +-&gt; expand -&gt; BN -&gt; GRU -&gt; BN -+</span>
<span class="sd">            input --|       stride = 10            |- concat -&gt; Dense(linear)</span>
<span class="sd">                    +-&gt; expand -&gt; BN -&gt; GRU -&gt; BN -+</span>

<span class="sd">        (BN: batch normalization)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                 <span class="n">l2</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                 <span class="o">*</span><span class="n">args</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Alpha net v3.</span>

<span class="sd">        Notes:</span>
<span class="sd">            alpha net v3 版本的全tensorflow实现，结构详见代码展开</span>

<span class="sd">        Args:</span>
<span class="sd">            dropout: 跟在特征扩张以及Batch Normalization之后的dropout，默认无dropout</span>
<span class="sd">            l2: 输出层的l2-regularization参数</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlphaNetV3</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l2</span> <span class="o">=</span> <span class="n">l2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expanded10</span> <span class="o">=</span> <span class="n">FeatureExpansion</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expanded5</span> <span class="o">=</span> <span class="n">FeatureExpansion</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized10</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized5</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout10</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout5</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru10</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru5</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized10_2</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized5_2</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">concat</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">_tfl</span><span class="o">.</span><span class="n">Concatenate</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
                                  <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;truncated_normal&quot;</span><span class="p">,</span>
                                  <span class="n">kernel_regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;计算逻辑实现.&quot;&quot;&quot;</span>
        <span class="n">expanded10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expanded10</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">expanded5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expanded5</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">normalized10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized10</span><span class="p">(</span><span class="n">expanded10</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">normalized5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized5</span><span class="p">(</span><span class="n">expanded5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">dropout10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout10</span><span class="p">(</span><span class="n">normalized10</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">dropout5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout5</span><span class="p">(</span><span class="n">normalized5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">gru10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru10</span><span class="p">(</span><span class="n">dropout10</span><span class="p">)</span>
        <span class="n">gru5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru5</span><span class="p">(</span><span class="n">dropout5</span><span class="p">)</span>
        <span class="n">normalized10_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized10_2</span><span class="p">(</span><span class="n">gru10</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">normalized5_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized5_2</span><span class="p">(</span><span class="n">gru5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">concat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">normalized10_2</span><span class="p">,</span> <span class="n">normalized5_2</span><span class="p">])</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">(</span><span class="n">concat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>

    <span class="k">def</span> <span class="nf">compile</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">_tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
                <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;MSE&quot;</span><span class="p">,</span>
                <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">loss_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">weighted_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">steps_per_execution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;设置优化器、loss、metric等.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                        <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                        <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
                        <span class="n">loss_weights</span><span class="o">=</span><span class="n">loss_weights</span><span class="p">,</span>
                        <span class="n">weighted_metrics</span><span class="o">=</span><span class="n">weighted_metrics</span><span class="p">,</span>
                        <span class="n">run_eagerly</span><span class="o">=</span><span class="n">run_eagerly</span><span class="p">,</span>
                        <span class="n">steps_per_execution</span><span class="o">=</span><span class="n">steps_per_execution</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;dropout&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
                       <span class="s1">&#39;l2&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>
</pre></div>

        </details>

            <div class="docstring"><p>alpha net v3版本模型.</p>

<h6 id="notes">Notes</h6>

<blockquote>
  <p>复现华泰金工 alpha net V3 版本
  ::</p>

<pre><code>input: (batch_size, history time steps, features)

                stride = 5
        +-&gt; expand -&gt; BN -&gt; GRU -&gt; BN -+
input --|       stride = 10            |- concat -&gt; Dense(linear)
        +-&gt; expand -&gt; BN -&gt; GRU -&gt; BN -+
</code></pre>
  
  <p>(BN: batch normalization)</p>
</blockquote>
</div>


                            <div id="AlphaNetV3.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#AlphaNetV3.__init__">#&nbsp;&nbsp</a>

        
            <span class="name">AlphaNetV3</span><span class="signature">(dropout=0.0, l2=0.001, *args, **kwargs)</span>
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                 <span class="n">l2</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                 <span class="o">*</span><span class="n">args</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Alpha net v3.</span>

<span class="sd">        Notes:</span>
<span class="sd">            alpha net v3 版本的全tensorflow实现，结构详见代码展开</span>

<span class="sd">        Args:</span>
<span class="sd">            dropout: 跟在特征扩张以及Batch Normalization之后的dropout，默认无dropout</span>
<span class="sd">            l2: 输出层的l2-regularization参数</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlphaNetV3</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l2</span> <span class="o">=</span> <span class="n">l2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expanded10</span> <span class="o">=</span> <span class="n">FeatureExpansion</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expanded5</span> <span class="o">=</span> <span class="n">FeatureExpansion</span><span class="p">(</span><span class="n">stride</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized10</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized5</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout10</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout5</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru10</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru5</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized10_2</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized5_2</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">concat</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">_tfl</span><span class="o">.</span><span class="n">Concatenate</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span> <span class="o">=</span> <span class="n">_tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">_tfl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
                                  <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;truncated_normal&quot;</span><span class="p">,</span>
                                  <span class="n">kernel_regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span><span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>Alpha net v3.</p>

<h6 id="notes">Notes</h6>

<blockquote>
  <p>alpha net v3 版本的全tensorflow实现，结构详见代码展开</p>
</blockquote>

<h6 id="args">Args</h6>

<ul>
<li><strong>dropout:</strong>  跟在特征扩张以及Batch Normalization之后的dropout，默认无dropout</li>
<li><strong>l2:</strong>  输出层的l2-regularization参数</li>
</ul>
</div>


                            </div>
                            <div id="AlphaNetV3.call" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#AlphaNetV3.call">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">call</span><span class="signature">(self, inputs, training=None, mask=None)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;计算逻辑实现.&quot;&quot;&quot;</span>
        <span class="n">expanded10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expanded10</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">expanded5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expanded5</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">normalized10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized10</span><span class="p">(</span><span class="n">expanded10</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">normalized5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized5</span><span class="p">(</span><span class="n">expanded5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">dropout10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout10</span><span class="p">(</span><span class="n">normalized10</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">dropout5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout5</span><span class="p">(</span><span class="n">normalized5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">gru10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru10</span><span class="p">(</span><span class="n">dropout10</span><span class="p">)</span>
        <span class="n">gru5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru5</span><span class="p">(</span><span class="n">dropout5</span><span class="p">)</span>
        <span class="n">normalized10_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized10_2</span><span class="p">(</span><span class="n">gru10</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">normalized5_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized5_2</span><span class="p">(</span><span class="n">gru5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">concat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">normalized10_2</span><span class="p">,</span> <span class="n">normalized5_2</span><span class="p">])</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">(</span><span class="n">concat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>

        </details>

            <div class="docstring"><p>计算逻辑实现.</p>
</div>


                            </div>
                            <div id="AlphaNetV3.compile" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#AlphaNetV3.compile">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">compile</span><span class="signature">(
    self,
    optimizer=&lt;tensorflow.python.keras.optimizer_v2.adam.Adam object&gt;,
    loss=&#39;MSE&#39;,
    metrics=None,
    loss_weights=None,
    weighted_metrics=None,
    run_eagerly=None,
    steps_per_execution=None,
    **kwargs
)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">compile</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">_tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
                <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;MSE&quot;</span><span class="p">,</span>
                <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">loss_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">weighted_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">steps_per_execution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;设置优化器、loss、metric等.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                        <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                        <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
                        <span class="n">loss_weights</span><span class="o">=</span><span class="n">loss_weights</span><span class="p">,</span>
                        <span class="n">weighted_metrics</span><span class="o">=</span><span class="n">weighted_metrics</span><span class="p">,</span>
                        <span class="n">run_eagerly</span><span class="o">=</span><span class="n">run_eagerly</span><span class="p">,</span>
                        <span class="n">steps_per_execution</span><span class="o">=</span><span class="n">steps_per_execution</span><span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>设置优化器、loss、metric等.</p>
</div>


                            </div>
                            <div id="AlphaNetV3.get_config" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#AlphaNetV3.get_config">#&nbsp;&nbsp</a>

        
            <span class="def">def</span>
            <span class="name">get_config</span><span class="signature">(self)</span>:
    </div>

                <details>
            <summary>View Source</summary>
            <div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;获取参数，保存模型需要的函数.&quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;dropout&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
                       <span class="s1">&#39;l2&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span>
</pre></div>

        </details>

            <div class="docstring"><p>获取参数，保存模型需要的函数.</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>tensorflow.python.keras.engine.training.Model</dt>
                                <dd id="AlphaNetV3.build" class="function">build</dd>
                <dd id="AlphaNetV3.metrics" class="variable">metrics</dd>
                <dd id="AlphaNetV3.metrics_names" class="variable">metrics_names</dd>
                <dd id="AlphaNetV3.distribute_strategy" class="variable">distribute_strategy</dd>
                <dd id="AlphaNetV3.run_eagerly" class="variable">run_eagerly</dd>
                <dd id="AlphaNetV3.train_step" class="function">train_step</dd>
                <dd id="AlphaNetV3.make_train_function" class="function">make_train_function</dd>
                <dd id="AlphaNetV3.fit" class="function">fit</dd>
                <dd id="AlphaNetV3.test_step" class="function">test_step</dd>
                <dd id="AlphaNetV3.make_test_function" class="function">make_test_function</dd>
                <dd id="AlphaNetV3.evaluate" class="function">evaluate</dd>
                <dd id="AlphaNetV3.predict_step" class="function">predict_step</dd>
                <dd id="AlphaNetV3.make_predict_function" class="function">make_predict_function</dd>
                <dd id="AlphaNetV3.predict" class="function">predict</dd>
                <dd id="AlphaNetV3.reset_metrics" class="function">reset_metrics</dd>
                <dd id="AlphaNetV3.train_on_batch" class="function">train_on_batch</dd>
                <dd id="AlphaNetV3.test_on_batch" class="function">test_on_batch</dd>
                <dd id="AlphaNetV3.predict_on_batch" class="function">predict_on_batch</dd>
                <dd id="AlphaNetV3.fit_generator" class="function">fit_generator</dd>
                <dd id="AlphaNetV3.evaluate_generator" class="function">evaluate_generator</dd>
                <dd id="AlphaNetV3.predict_generator" class="function">predict_generator</dd>
                <dd id="AlphaNetV3.trainable_weights" class="variable">trainable_weights</dd>
                <dd id="AlphaNetV3.non_trainable_weights" class="variable">non_trainable_weights</dd>
                <dd id="AlphaNetV3.get_weights" class="function">get_weights</dd>
                <dd id="AlphaNetV3.save" class="function">save</dd>
                <dd id="AlphaNetV3.save_weights" class="function">save_weights</dd>
                <dd id="AlphaNetV3.load_weights" class="function">load_weights</dd>
                <dd id="AlphaNetV3.from_config" class="function">from_config</dd>
                <dd id="AlphaNetV3.to_json" class="function">to_json</dd>
                <dd id="AlphaNetV3.to_yaml" class="function">to_yaml</dd>
                <dd id="AlphaNetV3.reset_states" class="function">reset_states</dd>
                <dd id="AlphaNetV3.state_updates" class="variable">state_updates</dd>
                <dd id="AlphaNetV3.weights" class="variable">weights</dd>
                <dd id="AlphaNetV3.summary" class="function">summary</dd>
                <dd id="AlphaNetV3.layers" class="variable">layers</dd>
                <dd id="AlphaNetV3.get_layer" class="function">get_layer</dd>

            </div>
            <div><dt>tensorflow.python.keras.engine.base_layer.Layer</dt>
                                <dd id="AlphaNetV3.add_weight" class="function">add_weight</dd>
                <dd id="AlphaNetV3.compute_output_shape" class="function">compute_output_shape</dd>
                <dd id="AlphaNetV3.compute_output_signature" class="function">compute_output_signature</dd>
                <dd id="AlphaNetV3.compute_mask" class="function">compute_mask</dd>
                <dd id="AlphaNetV3.dtype" class="variable">dtype</dd>
                <dd id="AlphaNetV3.name" class="variable">name</dd>
                <dd id="AlphaNetV3.supports_masking" class="variable">supports_masking</dd>
                <dd id="AlphaNetV3.dynamic" class="variable">dynamic</dd>
                <dd id="AlphaNetV3.stateful" class="variable">stateful</dd>
                <dd id="AlphaNetV3.trainable" class="variable">trainable</dd>
                <dd id="AlphaNetV3.activity_regularizer" class="variable">activity_regularizer</dd>
                <dd id="AlphaNetV3.input_spec" class="variable">input_spec</dd>
                <dd id="AlphaNetV3.updates" class="variable">updates</dd>
                <dd id="AlphaNetV3.losses" class="variable">losses</dd>
                <dd id="AlphaNetV3.add_loss" class="function">add_loss</dd>
                <dd id="AlphaNetV3.add_metric" class="function">add_metric</dd>
                <dd id="AlphaNetV3.add_update" class="function">add_update</dd>
                <dd id="AlphaNetV3.set_weights" class="function">set_weights</dd>
                <dd id="AlphaNetV3.get_updates_for" class="function">get_updates_for</dd>
                <dd id="AlphaNetV3.get_losses_for" class="function">get_losses_for</dd>
                <dd id="AlphaNetV3.get_input_mask_at" class="function">get_input_mask_at</dd>
                <dd id="AlphaNetV3.get_output_mask_at" class="function">get_output_mask_at</dd>
                <dd id="AlphaNetV3.input_mask" class="variable">input_mask</dd>
                <dd id="AlphaNetV3.output_mask" class="variable">output_mask</dd>
                <dd id="AlphaNetV3.get_input_shape_at" class="function">get_input_shape_at</dd>
                <dd id="AlphaNetV3.get_output_shape_at" class="function">get_output_shape_at</dd>
                <dd id="AlphaNetV3.get_input_at" class="function">get_input_at</dd>
                <dd id="AlphaNetV3.get_output_at" class="function">get_output_at</dd>
                <dd id="AlphaNetV3.input" class="variable">input</dd>
                <dd id="AlphaNetV3.output" class="variable">output</dd>
                <dd id="AlphaNetV3.input_shape" class="variable">input_shape</dd>
                <dd id="AlphaNetV3.count_params" class="function">count_params</dd>
                <dd id="AlphaNetV3.output_shape" class="variable">output_shape</dd>
                <dd id="AlphaNetV3.inbound_nodes" class="variable">inbound_nodes</dd>
                <dd id="AlphaNetV3.outbound_nodes" class="variable">outbound_nodes</dd>
                <dd id="AlphaNetV3.apply" class="function">apply</dd>
                <dd id="AlphaNetV3.add_variable" class="function">add_variable</dd>
                <dd id="AlphaNetV3.variables" class="variable">variables</dd>
                <dd id="AlphaNetV3.trainable_variables" class="variable">trainable_variables</dd>
                <dd id="AlphaNetV3.non_trainable_variables" class="variable">non_trainable_variables</dd>
                <dd id="AlphaNetV3.dtype_policy" class="variable">dtype_policy</dd>
                <dd id="AlphaNetV3.compute_dtype" class="variable">compute_dtype</dd>
                <dd id="AlphaNetV3.variable_dtype" class="variable">variable_dtype</dd>

            </div>
            <div><dt>tensorflow.python.module.module.Module</dt>
                                <dd id="AlphaNetV3.name_scope" class="variable">name_scope</dd>
                <dd id="AlphaNetV3.submodules" class="variable">submodules</dd>
                <dd id="AlphaNetV3.with_name_scope" class="function">with_name_scope</dd>

            </div>
                                </dl>
                            </div>
                </section>
    </main>
            <script>/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();</script>
            <script>
                function escapeHTML(html) {
                    return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
                }

                const originalContent = document.querySelector("main.pdoc");
                let currentContent = originalContent;

                function setContent(innerHTML) {
                    let elem;
                    if (innerHTML) {
                        elem = document.createElement("main");
                        elem.classList.add("pdoc");
                        elem.innerHTML = innerHTML;
                    } else {
                        elem = originalContent;
                    }
                    if (currentContent !== elem) {
                        currentContent.replaceWith(elem);
                        currentContent = elem;
                    }
                }

                function getSearchTerm() {
                    return (new URL(window.location)).searchParams.get("search");
                }

                const searchBox = document.querySelector(".pdoc input[type=search]");
                searchBox.addEventListener("input", function () {
                    let url = new URL(window.location);
                    if (searchBox.value.trim()) {
                        url.hash = "";
                        url.searchParams.set("search", searchBox.value);
                    } else {
                        url.searchParams.delete("search");
                    }
                    history.replaceState("", "", url.toString());
                    onInput();
                });
                window.addEventListener("popstate", onInput);


                let searchIndex, searchErr;

                async function initialize() {
                    let docs;
                    try {
                        let resp = await fetch("search.json");
                        docs = await resp.json();
                    } catch (e) {
                        searchErr = "Cannot fetch search index.";
                        throw e;
                    }

                    // Also split on html tags. this is a cheap heuristic, but good enough.
                    elasticlunr.tokenizer.setSeperator(/[\s\-.;&]+|<[^>]*>/);

                    if (docs._isPrebuiltIndex) {
                        console.info("using precompiled search index");
                        searchIndex = elasticlunr.Index.load(docs);
                    } else {
                        console.time("building search index");
                        searchIndex = elasticlunr(function () {
                            this.addField('qualname');
                            this.addField('fullname');
                            this.addField('doc');
                            this.setRef('fullname');
                        });
                        for (let doc of docs) {
                            searchIndex.addDoc(doc);
                        }
                        console.timeEnd("building search index");
                    }
                    onInput();

                    document.querySelector("nav.pdoc").addEventListener("click", e => {
                        if (e.target.hash) {
                            searchBox.value = "";
                            searchBox.dispatchEvent(new Event("input"));
                        }
                    });
                }

                function onInput() {
                    setContent((() => {
                        const search = getSearchTerm();
                        if (!search) {
                            return null
                        }
                        if (searchErr) {
                            return `<h3>Error: ${searchErr}</h3>`
                        }
                        if (!searchIndex) {
                            return "<h3>Searching...</h3>"
                        }

                        window.scrollTo({top: 0, left: 0, behavior: 'auto'});

                        const results = searchIndex.search(search, {
                            fields: {
                                qualname: {boost: 4},
                                fullname: {boost: 2},
                                doc: {boost: 1},
                            },
                            expand: true
                        });

                        let html;
                        if (results.length === 0) {
                            html = `No search results for '${escapeHTML(search)}'.`
                        } else {
                            html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(search)}'.</h4>`;
                        }
                        for (let result of results.slice(0, 10)) {
                            let doc = result.doc;
                            let url = `${doc.modulename.replaceAll(".", "/")}.html`;
                            if (doc.qualname) {
                                url += `#${doc.qualname}`;
                            }

                            let heading;
                            switch (result.doc.type) {
                                case "function":
                                    heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span><span class="signature">(${doc.parameters.join(", ")})</span>`;
                                    break;
                                case "class":
                                    heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                                    break;
                                default:
                                    heading = `<span class="name">${doc.fullname}</span>`;
                                    break;
                            }
                            html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.type}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

                        }
                        return html;
                    })());
                }

                if (getSearchTerm()) {
                    initialize();
                    searchBox.value = getSearchTerm();
                    onInput();
                } else {
                    searchBox.addEventListener("focus", initialize, {once: true});
                }

                searchBox.addEventListener("keydown", e => {
                    if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
                        let focused = currentContent.querySelector(".search-result.focused");
                        if (!focused) {
                            currentContent.querySelector(".search-result").classList.add("focused");
                        } else if (
                            e.key === "ArrowDown"
                            && focused.nextElementSibling
                            && focused.nextElementSibling.classList.contains("search-result")
                        ) {
                            focused.classList.remove("focused");
                            focused.nextElementSibling.classList.add("focused");
                            focused.nextElementSibling.scrollIntoView({
                                behavior: "smooth",
                                block: "nearest",
                                inline: "nearest"
                            });
                        } else if (
                            e.key === "ArrowUp"
                            && focused.previousElementSibling
                            && focused.previousElementSibling.classList.contains("search-result")
                        ) {
                            focused.classList.remove("focused");
                            focused.previousElementSibling.classList.add("focused");
                            focused.previousElementSibling.scrollIntoView({
                                behavior: "smooth",
                                block: "nearest",
                                inline: "nearest"
                            });
                        } else if (
                            e.key === "Enter"
                        ) {
                            focused.querySelector("a").click();
                        }
                    }
                });
            </script>
</body>
</html>